{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook preprocesses the data from Davidson et al. (2017) and pickles it for future use.\n",
    "\n",
    "It pickles two datasets. One with the original hate speech class, and another with the breakdown of the hate class into directed and generalized hate speech.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:20:58.816676Z",
     "start_time": "2020-02-10T05:20:48.309518Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import preprocess, create_lookup_tables, create_pad_fn, pad_tweets,\\\n",
    "                  hate_classification, change_hate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:20:58.910533Z",
     "start_time": "2020-02-10T05:20:58.819689Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/labeled_data.csv\", index_col=0)\n",
    "raw_tweets = df.tweet\n",
    "raw_labels = df[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:20:58.944449Z",
     "start_time": "2020-02-10T05:20:58.913403Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:20:59.937083Z",
     "start_time": "2020-02-10T05:20:58.951519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a raw tweet:\n",
      "\"@Almightywayne__: @JetsAndASwisher @Gook____ bitch fuck u http://t.co/pXmGA68NC1\" maybe you'll get better. Just http://t.co/TPreVwfq0S\n",
      "\n",
      "Its cleaned version is:\n",
      " ||Quotation_Mark|| MENTIONHERE : MENTIONHERE MENTIONHERE bitch fuck u URLHERE ||Quotation_Mark|| maybe you'll get better ||Period|| just URLHERE \n"
     ]
    }
   ],
   "source": [
    "tweets = raw_tweets.map(preprocess)\n",
    "print(\"Example of a raw tweet:\\n{}\".format(raw_tweets[68]))\n",
    "print(\"\\nIts cleaned version is:\\n{}\".format(preprocess(raw_tweets[68])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.023304Z",
     "start_time": "2020-02-10T05:20:59.940077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24783.000000\n",
       "mean        16.729936\n",
       "std          8.445555\n",
       "min          1.000000\n",
       "25%         10.000000\n",
       "50%         16.000000\n",
       "75%         23.000000\n",
       "max         95.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cleaned tweets\n",
    "df[\"clean_tweet\"] = tweets\n",
    "\n",
    "# Get their word count\n",
    "df[\"word_count\"] = df.clean_tweet.apply(lambda x : len(x.split()))\n",
    "\n",
    "df.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.079501Z",
     "start_time": "2020-02-10T05:21:00.032285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>#Yankees</td>\n",
       "      <td>HASHTAGHERE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24147</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>bitches</td>\n",
       "      <td>bitches</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24218</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>coons</td>\n",
       "      <td>coons</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24869</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pussy</td>\n",
       "      <td>pussy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class     tweet  \\\n",
       "821        3            0                   0        3      2  #Yankees   \n",
       "24147      3            0                   3        0      1   bitches   \n",
       "24218      3            3                   0        0      0     coons   \n",
       "24869      3            0                   3        0      1     pussy   \n",
       "\n",
       "         clean_tweet  word_count  \n",
       "821     HASHTAGHERE            1  \n",
       "24147        bitches           1  \n",
       "24218          coons           1  \n",
       "24869          pussy           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tweets with the minimum word count\n",
    "df.loc[df.word_count == df.word_count.min(),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Let's check the tweet(s) with the maximum word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.109356Z",
     "start_time": "2020-02-10T05:21:00.083488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22953</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Was finna slit my eyebrows up in the shop but ...</td>\n",
       "      <td>was finna slit my eyebrows up in the shop but ...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "22953      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \\\n",
       "22953  Was finna slit my eyebrows up in the shop but ...   \n",
       "\n",
       "                                             clean_tweet  word_count  \n",
       "22953  was finna slit my eyebrows up in the shop but ...          95  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tweets with the maximum length\n",
    "df.loc[df.word_count == df.word_count.max(),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something strange going on. Let's check the tweet again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.133297Z",
     "start_time": "2020-02-10T05:21:00.117336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Was finna slit my eyebrows up in the shop but nahhhhhh.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.word_count == df.word_count.max(),].tweet.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet contains a lot of new lines. It's hard to know why, but I'll choose to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.183173Z",
     "start_time": "2020-02-10T05:21:00.138282Z"
    }
   },
   "outputs": [],
   "source": [
    "old_tweet = df.loc[df.word_count == df.word_count.max(),].tweet.values[0]\n",
    "new_tweet = old_tweet[:old_tweet.find(\"\\r\")]\n",
    "df.loc[df.word_count == df.word_count.max(), \"tweet\"] = new_tweet\n",
    "df.loc[df.word_count == df.word_count.max(), \"clean_tweet\"] = preprocess(new_tweet)\n",
    "df.loc[df.word_count == df.word_count.max(), \"word_count\"] = len(preprocess(new_tweet).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.214381Z",
     "start_time": "2020-02-10T05:21:00.186164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22953</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Was finna slit my eyebrows up in the shop but ...</td>\n",
       "      <td>was finna slit my eyebrows up in the shop but ...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "22953      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \\\n",
       "22953  Was finna slit my eyebrows up in the shop but ...   \n",
       "\n",
       "                                             clean_tweet  word_count  \n",
       "22953  was finna slit my eyebrows up in the shop but ...          94  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tweets with the maximum length\n",
    "df.loc[df.word_count == df.word_count.max(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.236878Z",
     "start_time": "2020-02-10T05:21:00.218289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was finna slit my eyebrows up in the shop but nahhhhhh ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| ||Period|| ||Return|| '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.word_count == df.word_count.max(),].clean_tweet.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sighes. Well, format-wise it is okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.448163Z",
     "start_time": "2020-02-10T05:21:00.238806Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab = create_lookup_tables(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.460224Z",
     "start_time": "2020-02-10T05:21:00.450105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the vocabulary is: 21134 tokens.\n",
      "These are 10 randomly sample words in the vocabulary:\n",
      "['ao', 'packers', \"perry's\", '*hoes', 'santa', 'caught', 'fasho', 'slide', 'blasted', '\\U000fe32c']\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the vocabulary is: {} tokens.\".format(len(vocab_to_int)))\n",
    "vocab = list(vocab_to_int.keys())\n",
    "np.random.shuffle(vocab)\n",
    "print(\"These are 10 randomly sample words in the vocabulary:\\n{}\".format(vocab[:10]))\n",
    "del vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Padding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:00.623507Z",
     "start_time": "2020-02-10T05:21:00.462197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  ||Quotation_Mark|| keeks is a bitch she curves everyone ||Quotation_Mark|| lol i walked into a conversation like this ||Period|| smh\n"
     ]
    }
   ],
   "source": [
    "# Hemker sets the sentence length to 100. We'll do the same here for consistency, but\n",
    "# note that the max sentence length in our dataset is actually 91.\n",
    "MAX_LENGTH = 100  # df.word_count.max()\n",
    "pad_tweets = create_pad_fn(MAX_LENGTH)\n",
    "df[\"padded_tweets\"] = df.clean_tweet.map(pad_tweets)\n",
    "print(df.padded_tweets[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:01.836266Z",
     "start_time": "2020-02-10T05:21:00.625476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0 18159   869 10914\n",
      " 13793 13942 20385 11263  7057 18159 21040 11659 14570 19699 13793 10306\n",
      " 15907  9011 12074  9785]\n"
     ]
    }
   ],
   "source": [
    "tweets_ints = np.array([[vocab_to_int[word] for word in tweet.split()] for tweet in df.padded_tweets.values])\n",
    "print(tweets_ints[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hate Subclass Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:02.368949Z",
     "start_time": "2020-02-10T05:21:01.841250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a hateful tweet: \n",
      " ||Quotation_Mark|| we're out here ||Comma|| and we're queer ||Exclamation_Mark|| ||Quotation_Mark|| ||Return|| ||Quotation_Mark|| 2 ||Comma|| 4 ||Comma|| 6 ||Comma|| hut ||Exclamation_Mark|| we like it in our butt ||Exclamation_Mark|| ||Quotation_Mark|| \n",
      "Its type of hate speech is: Generalized\n",
      "\n",
      "Example of a hateful tweet:\n",
      " ||Quotation_Mark|| MENTIONHERE : jackies a retard HASHTAGHERE ||Quotation_Mark|| at least i can make a grilled cheese ||Exclamation_Mark|| \n",
      "Its type of hate speech is: Directed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hate_tweets = tweets[df[\"class\"] == 0].values\n",
    "_hate_prnt = lambda x : \"Generalized\" if hate_classification(x) == 4 else \"Directed\"\n",
    "\n",
    "print(\"Example of a hateful tweet: \\n{}\".format(hate_tweets[20]))\n",
    "print(\"Its type of hate speech is: {}\\n\".format(_hate_prnt(hate_tweets[20])))\n",
    "\n",
    "print(\"Example of a hateful tweet:\\n{}\".format(hate_tweets[10]))\n",
    "print(\"Its type of hate speech is: {}\\n\".format(_hate_prnt(hate_tweets[10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change hate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:07.984729Z",
     "start_time": "2020-02-10T05:21:02.372332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19190\n",
       "1     4163\n",
       "2      954\n",
       "3      476\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = change_hate_labels(tweets, raw_labels)\n",
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:08.001655Z",
     "start_time": "2020-02-10T05:21:07.986664Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"data/tweets\", tweets_ints)\n",
    "np.save(\"data/hate_original\", raw_labels)\n",
    "np.save(\"data/hate_breakdown\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:08.295365Z",
     "start_time": "2020-02-10T05:21:08.003637Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('vocab_to_int.json', 'w') as f:\n",
    "    json.dump(vocab_to_int, f)\n",
    "    \n",
    "with open('int_to_vocab.json', 'w') as f:\n",
    "    json.dump(int_to_vocab, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
