{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication Summary\n",
    "\n",
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoWV + GBDT\n",
    "\n",
    "__Command:__\n",
    "`!python BoWV.py -m gradient_boosting --loss deviance --estimators 500 --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.765 (vs. 0.800)\n",
    "\n",
    "Recall(avg): 0.774 (vs. 0.802)\n",
    "\n",
    "F1-score(avg): 0.759 (0.801)\n",
    "\n",
    "__Reflection:__\n",
    "They are missing the hyperpararmeteers. Regardless, it is pretty far off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "GloVe model loaded successfully.\n",
      "Tweets selected: 16905\n",
      "Features and labels loaded from pickled files.\n",
      "Model Type: gradient_boosting\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 19.6min finished\n",
      "Precision(avg): 0.765 (+/- 0.013)\n",
      "Recall(avg): 0.774 (+/- 0.012)\n",
      "F1-score(avg): 0.759 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python BoWV.py -m gradient_boosting --loss deviance --estimators 500 --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoWV + Balanced SVM\n",
    "\n",
    "__Command:__\n",
    "`!python BoWV.py -m svm --kernel rbf --class_weight balanced --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.748 (vs. 0.791)\n",
    "\n",
    "Recall(avg): 0.675 (vs. 0.788)\n",
    "\n",
    "F1-score(avg): 0.689 (0.789)\n",
    "\n",
    "__Reflection:__ SVMs are very sensitive to the choice of hyperparameters. We see that the default `rbf` kernel has a performance much worse than reported by the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "GloVe model loaded successfully.\n",
      "Tweets selected: 16905\n",
      "Features and labels loaded from pickled files.\n",
      "Model Type: svm\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/vini/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 13.5min finished\n",
      "Precision(avg): 0.748 (+/- 0.015)\n",
      "Recall(avg): 0.675 (+/- 0.023)\n",
      "F1-score(avg): 0.689 (+/- 0.021)\n"
     ]
    }
   ],
   "source": [
    "!python BoWV.py -m svm --kernel rbf --class_weight balanced --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + GBDT\n",
    "\n",
    "__Command:__\n",
    "`!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.826 (vs. 0.819)\n",
    "\n",
    "Recall(avg): 0.817 (vs. 0.807)\n",
    "\n",
    "F1-score(avg): 0.801 (vs. 0.813)\n",
    "\n",
    "__Reflection:__\n",
    "Close enough. Notice that the second try enables inverse-document-frequency reweighting (i.e., `--use-inverse-doc-freq`), which does not affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.4min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.7min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV] ................................................. , total=14.2min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 59.7min finished\n",
      "Precision(avg): 0.826 (+/- 0.014)\n",
      "Recall(avg): 0.817 (+/- 0.013)\n",
      "F1-score(avg): 0.801 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.3min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=16.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=14.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.0min\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV] ................................................. , total=14.2min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 59.6min finished\n",
      "Precision(avg): 0.825 (+/- 0.013)\n",
      "Recall(avg): 0.816 (+/- 0.013)\n",
      "F1-score(avg): 0.800 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove --use-inverse-doc-freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Balanced SVM\n",
    "\n",
    "__Command:__\n",
    "`!python tfidf.py -m tfidf_svm --kernel rbf --class_weight balanced --max_ngram 3 --jobs -2 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0. (vs. 0.816)\n",
    "\n",
    "Recall(avg): 0. (vs. 0.816)\n",
    "\n",
    "F1-score(avg): 0. (vs. 0.816)\n",
    "\n",
    "__Reflection:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_svm --kernel rbf --class_weight balanced --max_ngram 3 --jobs -2 --seed 42 --tokenizer glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
