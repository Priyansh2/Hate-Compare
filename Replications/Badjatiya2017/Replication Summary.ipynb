{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication Summary\n",
    "\n",
    "## Part A - Baselines\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Balanced SVM\n",
    "\n",
    "__Command:__\n",
    "`!python tfidf.py -m tfidf_svm --kernel rbf --class_weight balanced --max_ngram 3 --jobs -2 --seed 42 --tokenizer glove`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.823. (vs. 0.816)\n",
    "\n",
    "Recall(avg): 0.826 (vs. 0.816)\n",
    "\n",
    "F1-score(avg): 0.823 (vs. 0.816)\n",
    "\n",
    "__Reflection:__ Looks good!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_svm\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.6min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.6min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.7min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.2min\n",
      "[CV] ................................................. , total= 3.3min\n",
      "[CV] ................................................. , total= 3.7min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 24.7min finished\n",
      "Precision(avg): 0.823 (+/- 0.019)\n",
      "Recall(avg): 0.826 (+/- 0.019)\n",
      "F1-score(avg): 0.823 (+/- 0.019)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_svm --kernel rbf --class_weight balanced --max_ngram 3 --jobs -2 --seed 42 --tokenizer glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + GBDT\n",
    "\n",
    "__Command:__\n",
    "`!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.826 (vs. 0.819)\n",
    "\n",
    "Recall(avg): 0.817 (vs. 0.807)\n",
    "\n",
    "F1-score(avg): 0.801 (vs. 0.813)\n",
    "\n",
    "__Reflection:__\n",
    "Close enough. Notice that the second try enables inverse-document-frequency reweighting (i.e., `--use-inverse-doc-freq`), which does not affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.4min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.7min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV] ................................................. , total=14.2min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 59.7min finished\n",
      "Precision(avg): 0.826 (+/- 0.014)\n",
      "Recall(avg): 0.817 (+/- 0.013)\n",
      "F1-score(avg): 0.801 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.3min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=16.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=14.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.0min\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV] ................................................. , total=14.2min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 59.6min finished\n",
      "Precision(avg): 0.825 (+/- 0.013)\n",
      "Recall(avg): 0.816 (+/- 0.013)\n",
      "F1-score(avg): 0.800 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove --use-inverse-doc-freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoWV + Balanced SVM \n",
    "\n",
    "__Command:__\n",
    "`!python BoWV.py -m svm --kernel rbf --class_weight balanced --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.758 (vs. 0.791)\n",
    "\n",
    "Recall(avg): 0.692 (vs. 0.788)\n",
    "\n",
    "F1-score(avg): 0.705 (vs. 0.789)\n",
    "\n",
    "__Reflection:__ SVMs are very sensitive to the choice of hyperparameters. We see that the default `rbf` kernel has a performance much worse than reported by the paper. However, since the same SVM performs well in the tf-idf model and the gradient boosting estimator also underperforms in the BoWV model, we have reason to believe something is wrong with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "GloVe model loaded successfully.\n",
      "Tweets selected: 16905\n",
      "Features and labels loaded from pickled files.\n",
      "Model Type: svm\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 12.8min finished\n",
      "Precision(avg): 0.758 (+/- 0.017)\n",
      "Recall(avg): 0.692 (+/- 0.022)\n",
      "F1-score(avg): 0.705 (+/- 0.021)\n"
     ]
    }
   ],
   "source": [
    "!python BoWV.py -m svm --kernel rbf --class_weight balanced --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoWV + GBDT\n",
    "\n",
    "__Command:__\n",
    "`!python BoWV.py -m gradient_boosting --loss deviance --estimators 500 --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.765 (vs. 0.800)\n",
    "\n",
    "Recall(avg): 0.774 (vs. 0.802)\n",
    "\n",
    "F1-score(avg): 0.759 (vs. 0.801)\n",
    "\n",
    "__Reflection:__\n",
    "Similar to the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "GloVe model loaded successfully.\n",
      "Tweets selected: 16905\n",
      "Features and labels loaded from pickled files.\n",
      "Model Type: gradient_boosting\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 19.6min finished\n",
      "Precision(avg): 0.765 (+/- 0.013)\n",
      "Recall(avg): 0.774 (+/- 0.012)\n",
      "F1-score(avg): 0.759 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python BoWV.py -m gradient_boosting --loss deviance --estimators 500 --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - DNNs only\n",
    "---\n",
    "### CNN + Random Embedding\n",
    "\n",
    "__Command:__\n",
    "`!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights random --learn-embeddings`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.816 (vs. 0.813)\n",
    "\n",
    "Recall(avg): 0.816 (vs. 0.816)\n",
    "\n",
    "F1-score(avg): 0.816 (vs. 0.814)\n",
    "\n",
    "__Reflection:__\n",
    "Looks good! Note that the authors do not mention for how many epochs they trained the networks. I trained for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 28\n",
      "3450 embedding missed\n",
      "Model variation is CNN-rand\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 28, 200)       3402800     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 28, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 300)           240300      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 300)           0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 300)           0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             903         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 3)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,644,003\n",
      "Trainable params: 3,644,003\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "2019-10-05 20:29:58.269479: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.817434.\tAccuracy: 0.703571\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.708531.\tAccuracy: 0.732812\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.636865.\tAccuracy: 0.758185\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.408748.\tAccuracy: 0.838839\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.379630.\tAccuracy: 0.852344\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.359142.\tAccuracy: 0.859301\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.260756.\tAccuracy: 0.902232\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.243258.\tAccuracy: 0.908817\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.226457.\tAccuracy: 0.916146\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.169056.\tAccuracy: 0.942634\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.156666.\tAccuracy: 0.945759\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.147337.\tAccuracy: 0.948140\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.111978.\tAccuracy: 0.962946\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.103828.\tAccuracy: 0.965513\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.096984.\tAccuracy: 0.967411\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.086495.\tAccuracy: 0.971429\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.081599.\tAccuracy: 0.973103\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.076693.\tAccuracy: 0.975298\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.067275.\tAccuracy: 0.978348\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.064103.\tAccuracy: 0.979464\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.059071.\tAccuracy: 0.980729\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.055981.\tAccuracy: 0.981696\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.052424.\tAccuracy: 0.983036\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.049897.\tAccuracy: 0.984301\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.048847.\tAccuracy: 0.985714\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.046181.\tAccuracy: 0.985268\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.043066.\tAccuracy: 0.986012\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.042286.\tAccuracy: 0.986384\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.041050.\tAccuracy: 0.986496\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.037727.\tAccuracy: 0.987649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      1155\n",
      "           1       0.66      0.69      0.68       191\n",
      "           2       0.63      0.71      0.67       345\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1691\n",
      "   macro avg       0.72      0.74      0.73      1691\n",
      "weighted avg       0.79      0.79      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.741829.\tAccuracy: 0.701339\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.638864.\tAccuracy: 0.746429\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.576704.\tAccuracy: 0.770461\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.320548.\tAccuracy: 0.878125\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.280595.\tAccuracy: 0.892522\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.259678.\tAccuracy: 0.900893\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.180813.\tAccuracy: 0.935268\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.166230.\tAccuracy: 0.941071\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.153907.\tAccuracy: 0.945164\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.114378.\tAccuracy: 0.962054\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.109192.\tAccuracy: 0.962946\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.099530.\tAccuracy: 0.967262\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.084869.\tAccuracy: 0.971429\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.081089.\tAccuracy: 0.974107\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.076806.\tAccuracy: 0.974926\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.063769.\tAccuracy: 0.979911\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.064941.\tAccuracy: 0.977902\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.061077.\tAccuracy: 0.980060\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.056856.\tAccuracy: 0.982366\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.055999.\tAccuracy: 0.981362\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.052678.\tAccuracy: 0.982440\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.050007.\tAccuracy: 0.983259\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.047076.\tAccuracy: 0.984710\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.043164.\tAccuracy: 0.986384\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.046630.\tAccuracy: 0.983929\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.042948.\tAccuracy: 0.985045\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.041433.\tAccuracy: 0.986086\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.031941.\tAccuracy: 0.988393\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.034367.\tAccuracy: 0.988281\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.031496.\tAccuracy: 0.989807\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      1176\n",
      "           1       0.65      0.64      0.64       187\n",
      "           2       0.63      0.68      0.65       328\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1691\n",
      "   macro avg       0.71      0.72      0.72      1691\n",
      "weighted avg       0.79      0.79      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.845747.\tAccuracy: 0.675223\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.708180.\tAccuracy: 0.726897\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.637266.\tAccuracy: 0.753125\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.318868.\tAccuracy: 0.880357\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.285293.\tAccuracy: 0.892188\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.265327.\tAccuracy: 0.899926\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.184690.\tAccuracy: 0.931920\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.170531.\tAccuracy: 0.938504\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.159904.\tAccuracy: 0.943155\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.123474.\tAccuracy: 0.956250\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.117492.\tAccuracy: 0.959263\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.110053.\tAccuracy: 0.962054\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.099492.\tAccuracy: 0.969196\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.089882.\tAccuracy: 0.970759\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.084871.\tAccuracy: 0.972321\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.075133.\tAccuracy: 0.977232\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.070585.\tAccuracy: 0.978348\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.066739.\tAccuracy: 0.979390\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.067173.\tAccuracy: 0.977232\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.062504.\tAccuracy: 0.979464\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.058609.\tAccuracy: 0.980655\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.051348.\tAccuracy: 0.984152\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.050923.\tAccuracy: 0.984152\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.050077.\tAccuracy: 0.984821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.048335.\tAccuracy: 0.983929\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.047847.\tAccuracy: 0.984263\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.045784.\tAccuracy: 0.984970\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.045184.\tAccuracy: 0.986830\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.041895.\tAccuracy: 0.987388\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.040375.\tAccuracy: 0.987574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      1155\n",
      "           1       0.72      0.72      0.72       205\n",
      "           2       0.70      0.63      0.66       331\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1691\n",
      "   macro avg       0.76      0.74      0.75      1691\n",
      "weighted avg       0.81      0.81      0.81      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.873144.\tAccuracy: 0.660268\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.758676.\tAccuracy: 0.707924\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.685781.\tAccuracy: 0.737798\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.335062.\tAccuracy: 0.872991\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.306403.\tAccuracy: 0.883147\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.286844.\tAccuracy: 0.892262\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.197885.\tAccuracy: 0.922321\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.180309.\tAccuracy: 0.932924\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.169062.\tAccuracy: 0.937798\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.146411.\tAccuracy: 0.949330\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.136462.\tAccuracy: 0.952902\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.123929.\tAccuracy: 0.957738\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.104485.\tAccuracy: 0.964955\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.096997.\tAccuracy: 0.966629\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.094476.\tAccuracy: 0.966890\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.083348.\tAccuracy: 0.972545\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.079655.\tAccuracy: 0.972768\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.078083.\tAccuracy: 0.973065\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.080358.\tAccuracy: 0.973884\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.075825.\tAccuracy: 0.975670\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.070532.\tAccuracy: 0.976935\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.057403.\tAccuracy: 0.981027\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.054531.\tAccuracy: 0.983259\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.053226.\tAccuracy: 0.983929\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.054470.\tAccuracy: 0.982589\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.055452.\tAccuracy: 0.981808\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.052992.\tAccuracy: 0.982664\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.051838.\tAccuracy: 0.981920\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.049286.\tAccuracy: 0.983594\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.046053.\tAccuracy: 0.984896\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      1142\n",
      "           1       0.67      0.72      0.70       194\n",
      "           2       0.68      0.67      0.67       355\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1691\n",
      "   macro avg       0.74      0.75      0.74      1691\n",
      "weighted avg       0.80      0.80      0.80      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.030443.\tAccuracy: 0.653571\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.846493.\tAccuracy: 0.703125\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.756181.\tAccuracy: 0.729911\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.356508.\tAccuracy: 0.859375\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.335007.\tAccuracy: 0.870424\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.314582.\tAccuracy: 0.878497\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.225587.\tAccuracy: 0.915625\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.212232.\tAccuracy: 0.922433\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.197353.\tAccuracy: 0.927083\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.157946.\tAccuracy: 0.945536\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.146647.\tAccuracy: 0.948996\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.140991.\tAccuracy: 0.949330\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.127492.\tAccuracy: 0.957143\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.119982.\tAccuracy: 0.959263\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.112116.\tAccuracy: 0.961012\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.095283.\tAccuracy: 0.966295\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.091054.\tAccuracy: 0.968750\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.085856.\tAccuracy: 0.970685\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.079509.\tAccuracy: 0.971205\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.075539.\tAccuracy: 0.975000\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.071991.\tAccuracy: 0.975967\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.072181.\tAccuracy: 0.978795\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.069196.\tAccuracy: 0.979129\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.064370.\tAccuracy: 0.979911\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.060619.\tAccuracy: 0.980580\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.059743.\tAccuracy: 0.980580\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.056221.\tAccuracy: 0.981994\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.057842.\tAccuracy: 0.981473\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.055143.\tAccuracy: 0.983036\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.051413.\tAccuracy: 0.984077\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      1134\n",
      "           1       0.68      0.76      0.72       194\n",
      "           2       0.77      0.70      0.73       363\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1691\n",
      "   macro avg       0.77      0.78      0.77      1691\n",
      "weighted avg       0.83      0.82      0.82      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.086010.\tAccuracy: 0.645536\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.912377.\tAccuracy: 0.687500\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.812408.\tAccuracy: 0.717932\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.383573.\tAccuracy: 0.853348\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.362865.\tAccuracy: 0.860379\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.348255.\tAccuracy: 0.866369\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.239894.\tAccuracy: 0.911607\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.226785.\tAccuracy: 0.914844\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.215778.\tAccuracy: 0.919122\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.166850.\tAccuracy: 0.943304\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.161888.\tAccuracy: 0.942746\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.156976.\tAccuracy: 0.943527\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.129935.\tAccuracy: 0.949107\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.129147.\tAccuracy: 0.952567\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.122199.\tAccuracy: 0.956548\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.110243.\tAccuracy: 0.961607\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.105904.\tAccuracy: 0.964286\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.101130.\tAccuracy: 0.964955\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.085942.\tAccuracy: 0.971429\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.086407.\tAccuracy: 0.970871\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.082344.\tAccuracy: 0.972024\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.074290.\tAccuracy: 0.975893\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.073687.\tAccuracy: 0.976116\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.069361.\tAccuracy: 0.977381\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.064023.\tAccuracy: 0.982143\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.063304.\tAccuracy: 0.979799\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.061801.\tAccuracy: 0.980878\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.066123.\tAccuracy: 0.979018\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.062497.\tAccuracy: 0.979576\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.057990.\tAccuracy: 0.981771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1169\n",
      "           1       0.71      0.69      0.70       191\n",
      "           2       0.74      0.71      0.73       330\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1690\n",
      "   macro avg       0.78      0.76      0.77      1690\n",
      "weighted avg       0.83      0.83      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.025721.\tAccuracy: 0.643527\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.881616.\tAccuracy: 0.686049\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.798127.\tAccuracy: 0.713988\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.395786.\tAccuracy: 0.849777\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.370598.\tAccuracy: 0.857143\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.360065.\tAccuracy: 0.862277\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.253522.\tAccuracy: 0.900446\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.245093.\tAccuracy: 0.906920\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.235232.\tAccuracy: 0.909970\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.182785.\tAccuracy: 0.934375\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.178514.\tAccuracy: 0.935937\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.171130.\tAccuracy: 0.938690\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.139811.\tAccuracy: 0.951786\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.132658.\tAccuracy: 0.954464\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.128473.\tAccuracy: 0.955208\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.119439.\tAccuracy: 0.958259\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.119313.\tAccuracy: 0.958259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.112313.\tAccuracy: 0.960119\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.091431.\tAccuracy: 0.968750\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.095103.\tAccuracy: 0.966964\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.092931.\tAccuracy: 0.968229\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.083757.\tAccuracy: 0.970536\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.081412.\tAccuracy: 0.971205\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.077920.\tAccuracy: 0.972098\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.074322.\tAccuracy: 0.977679\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.073357.\tAccuracy: 0.977121\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.070471.\tAccuracy: 0.977753\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.063309.\tAccuracy: 0.979018\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.064530.\tAccuracy: 0.979799\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.060675.\tAccuracy: 0.981101\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1150\n",
      "           1       0.71      0.77      0.74       209\n",
      "           2       0.74      0.69      0.72       331\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1690\n",
      "   macro avg       0.78      0.78      0.78      1690\n",
      "weighted avg       0.83      0.83      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.081953.\tAccuracy: 0.642857\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.907646.\tAccuracy: 0.686607\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.817631.\tAccuracy: 0.712500\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.422137.\tAccuracy: 0.838839\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.396023.\tAccuracy: 0.848884\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.381934.\tAccuracy: 0.855804\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.279017.\tAccuracy: 0.893750\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.259378.\tAccuracy: 0.902790\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.249228.\tAccuracy: 0.906176\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.200524.\tAccuracy: 0.927455\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.194805.\tAccuracy: 0.930357\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.184805.\tAccuracy: 0.933333\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.152527.\tAccuracy: 0.947098\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.147619.\tAccuracy: 0.948438\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.145806.\tAccuracy: 0.949926\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.132028.\tAccuracy: 0.953571\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.129826.\tAccuracy: 0.954129\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.124836.\tAccuracy: 0.956696\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.111556.\tAccuracy: 0.962723\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.107441.\tAccuracy: 0.964174\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.103037.\tAccuracy: 0.964658\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.091168.\tAccuracy: 0.967187\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.085692.\tAccuracy: 0.969978\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.082382.\tAccuracy: 0.970982\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.083455.\tAccuracy: 0.972768\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.085550.\tAccuracy: 0.970759\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.082036.\tAccuracy: 0.972098\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.074428.\tAccuracy: 0.975893\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.072063.\tAccuracy: 0.976004\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.069377.\tAccuracy: 0.976562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      1119\n",
      "           1       0.75      0.70      0.72       209\n",
      "           2       0.76      0.67      0.71       362\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.79      0.76      0.77      1690\n",
      "weighted avg       0.82      0.82      0.82      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.175766.\tAccuracy: 0.636830\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.977132.\tAccuracy: 0.676228\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.876324.\tAccuracy: 0.700744\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.427631.\tAccuracy: 0.837946\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.404018.\tAccuracy: 0.843750\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.389585.\tAccuracy: 0.849033\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.287042.\tAccuracy: 0.892634\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.278534.\tAccuracy: 0.896094\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.266462.\tAccuracy: 0.899777\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.207592.\tAccuracy: 0.922545\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.199184.\tAccuracy: 0.926786\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.192718.\tAccuracy: 0.928423\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.168491.\tAccuracy: 0.939286\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.157843.\tAccuracy: 0.942076\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.151682.\tAccuracy: 0.944345\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.137562.\tAccuracy: 0.950223\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.130737.\tAccuracy: 0.953013\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.126870.\tAccuracy: 0.954688\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.114527.\tAccuracy: 0.960268\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.111821.\tAccuracy: 0.961049\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.105836.\tAccuracy: 0.963318\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.097152.\tAccuracy: 0.967634\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.094720.\tAccuracy: 0.968415\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.089455.\tAccuracy: 0.970536\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.087679.\tAccuracy: 0.968080\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.086162.\tAccuracy: 0.970089\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.081797.\tAccuracy: 0.971949\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.076790.\tAccuracy: 0.971652\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.075631.\tAccuracy: 0.972768\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.074066.\tAccuracy: 0.973512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      1166\n",
      "           1       0.73      0.76      0.74       194\n",
      "           2       0.76      0.76      0.76       330\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1690\n",
      "   macro avg       0.80      0.80      0.80      1690\n",
      "weighted avg       0.85      0.85      0.85      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.099484.\tAccuracy: 0.641518\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.940715.\tAccuracy: 0.680469\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.845013.\tAccuracy: 0.705952\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.426881.\tAccuracy: 0.839509\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.410145.\tAccuracy: 0.845536\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.400472.\tAccuracy: 0.848884\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.271658.\tAccuracy: 0.894420\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.271543.\tAccuracy: 0.896763\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.266153.\tAccuracy: 0.900000\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.206292.\tAccuracy: 0.922098\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.202747.\tAccuracy: 0.924107\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.196000.\tAccuracy: 0.927158\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.163729.\tAccuracy: 0.942187\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.162367.\tAccuracy: 0.943638\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.156732.\tAccuracy: 0.945759\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.132124.\tAccuracy: 0.952009\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.134406.\tAccuracy: 0.951562\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.131112.\tAccuracy: 0.952381\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.121331.\tAccuracy: 0.960045\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.115485.\tAccuracy: 0.960045\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.110096.\tAccuracy: 0.962277\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.099388.\tAccuracy: 0.962500\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.096222.\tAccuracy: 0.965625\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.091523.\tAccuracy: 0.968006\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.085379.\tAccuracy: 0.972991\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.081933.\tAccuracy: 0.973884\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.079609.\tAccuracy: 0.973735\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.075423.\tAccuracy: 0.977009\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.075728.\tAccuracy: 0.975446\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.072230.\tAccuracy: 0.976562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      1133\n",
      "           1       0.74      0.76      0.75       202\n",
      "           2       0.72      0.68      0.70       355\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.78      0.77      0.77      1690\n",
      "weighted avg       0.82      0.82      0.82      1690\n",
      "\n",
      "weighted results are\n",
      "average precision is 0.816428\n",
      "average recall is 0.816153\n",
      "average f1 is 0.815898\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights random --learn-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + GloVe\n",
    "\n",
    "__Command:__\n",
    "`!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights glove --learn-embeddings`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.836 (vs. 0.839)\n",
    "\n",
    "Recall(avg): 0.837 (vs. 0.840)\n",
    "\n",
    "F1-score(avg): 0.835 (vs. 0.839)\n",
    "\n",
    "__Reflection:__\n",
    "Close enough. Note that the authors do not mention for how many epochs they trained the networks. I trained for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 28\n",
      "3450 embedding missed\n",
      "Model variation is CNN-rand\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 28, 200)       3402800     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 28, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 300)           240300      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 300)           0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 300)           0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             903         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 3)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,644,003\n",
      "Trainable params: 3,644,003\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "2019-10-05 21:19:33.939638: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.611778.\tAccuracy: 0.764286\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.565139.\tAccuracy: 0.781473\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.542019.\tAccuracy: 0.787202\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.432527.\tAccuracy: 0.821205\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.421606.\tAccuracy: 0.829911\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.416893.\tAccuracy: 0.830729\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.350413.\tAccuracy: 0.855134\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.345401.\tAccuracy: 0.859598\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.336043.\tAccuracy: 0.863021\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.298232.\tAccuracy: 0.880357\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.281177.\tAccuracy: 0.888170\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.275736.\tAccuracy: 0.891667\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.234814.\tAccuracy: 0.908259\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.227032.\tAccuracy: 0.912612\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.223618.\tAccuracy: 0.913095\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.193898.\tAccuracy: 0.925446\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.185703.\tAccuracy: 0.928237\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.179902.\tAccuracy: 0.931696\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.158831.\tAccuracy: 0.943304\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.153652.\tAccuracy: 0.946205\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.151265.\tAccuracy: 0.946875\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.139895.\tAccuracy: 0.947991\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.132040.\tAccuracy: 0.950112\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.126786.\tAccuracy: 0.952679\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.123993.\tAccuracy: 0.955134\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.117963.\tAccuracy: 0.956808\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.112084.\tAccuracy: 0.959003\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.105629.\tAccuracy: 0.960714\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.101538.\tAccuracy: 0.963393\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.098139.\tAccuracy: 0.965104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1155\n",
      "           1       0.70      0.75      0.72       191\n",
      "           2       0.77      0.68      0.72       345\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.78      0.77      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.910258.\tAccuracy: 0.689955\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.762965.\tAccuracy: 0.728013\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.686802.\tAccuracy: 0.747470\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.448283.\tAccuracy: 0.819643\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.430603.\tAccuracy: 0.829799\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.424351.\tAccuracy: 0.831771\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.358919.\tAccuracy: 0.854018\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.356665.\tAccuracy: 0.857924\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.350463.\tAccuracy: 0.860193\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.298787.\tAccuracy: 0.885268\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.291575.\tAccuracy: 0.887723\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.285656.\tAccuracy: 0.888765\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.247718.\tAccuracy: 0.902455\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.245526.\tAccuracy: 0.903348\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.242210.\tAccuracy: 0.905134\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.209561.\tAccuracy: 0.920312\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.214087.\tAccuracy: 0.918973\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.205815.\tAccuracy: 0.922991\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.173755.\tAccuracy: 0.933036\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.175276.\tAccuracy: 0.933036\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.170539.\tAccuracy: 0.936161\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.156533.\tAccuracy: 0.941295\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.154781.\tAccuracy: 0.942299\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.150208.\tAccuracy: 0.944122\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.131109.\tAccuracy: 0.953348\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.133377.\tAccuracy: 0.951004\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.132783.\tAccuracy: 0.950818\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.131917.\tAccuracy: 0.952902\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.125384.\tAccuracy: 0.954911\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.121004.\tAccuracy: 0.955580\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1176\n",
      "           1       0.71      0.73      0.72       187\n",
      "           2       0.73      0.68      0.70       328\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.77      0.77      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.331867.\tAccuracy: 0.672321\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 1.015055.\tAccuracy: 0.715290\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.875632.\tAccuracy: 0.733929\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.455373.\tAccuracy: 0.824554\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.448806.\tAccuracy: 0.824888\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.441811.\tAccuracy: 0.826562\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.374208.\tAccuracy: 0.851562\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.374020.\tAccuracy: 0.855246\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.368251.\tAccuracy: 0.855804\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.322826.\tAccuracy: 0.870536\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.320571.\tAccuracy: 0.873772\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.312895.\tAccuracy: 0.878125\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.277698.\tAccuracy: 0.892634\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.274671.\tAccuracy: 0.894420\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.268798.\tAccuracy: 0.896726\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.230076.\tAccuracy: 0.909821\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.231869.\tAccuracy: 0.909152\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.227347.\tAccuracy: 0.912351\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.210331.\tAccuracy: 0.918973\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.206171.\tAccuracy: 0.922656\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.201034.\tAccuracy: 0.924628\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.175672.\tAccuracy: 0.935937\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.179118.\tAccuracy: 0.932813\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.176569.\tAccuracy: 0.933557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.157955.\tAccuracy: 0.942411\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.150249.\tAccuracy: 0.945871\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.150660.\tAccuracy: 0.944940\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.137948.\tAccuracy: 0.948438\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.137960.\tAccuracy: 0.949554\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.138997.\tAccuracy: 0.948363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1155\n",
      "           1       0.77      0.77      0.77       205\n",
      "           2       0.75      0.61      0.68       331\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.79      0.76      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.044777.\tAccuracy: 0.681696\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.878581.\tAccuracy: 0.714844\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.789872.\tAccuracy: 0.731845\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.463239.\tAccuracy: 0.815625\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.460207.\tAccuracy: 0.820424\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.455724.\tAccuracy: 0.823289\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.386483.\tAccuracy: 0.845536\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.381901.\tAccuracy: 0.847991\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.384460.\tAccuracy: 0.845015\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.324955.\tAccuracy: 0.866741\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.327501.\tAccuracy: 0.867634\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.324331.\tAccuracy: 0.870610\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.302589.\tAccuracy: 0.878125\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.294564.\tAccuracy: 0.882589\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.287421.\tAccuracy: 0.885863\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.248923.\tAccuracy: 0.902902\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.245493.\tAccuracy: 0.904018\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.243378.\tAccuracy: 0.904464\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.220995.\tAccuracy: 0.917188\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.218572.\tAccuracy: 0.916853\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.214416.\tAccuracy: 0.918155\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.182493.\tAccuracy: 0.929241\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.185008.\tAccuracy: 0.929129\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.184567.\tAccuracy: 0.929167\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.163794.\tAccuracy: 0.940625\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.166361.\tAccuracy: 0.939732\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.165542.\tAccuracy: 0.939881\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.156203.\tAccuracy: 0.941295\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.149761.\tAccuracy: 0.944866\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.146483.\tAccuracy: 0.946205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1142\n",
      "           1       0.72      0.70      0.71       194\n",
      "           2       0.81      0.64      0.72       355\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.80      0.75      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.468732.\tAccuracy: 0.656250\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 1.106551.\tAccuracy: 0.705469\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.943589.\tAccuracy: 0.723363\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.477379.\tAccuracy: 0.813839\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.475382.\tAccuracy: 0.814509\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.472581.\tAccuracy: 0.813765\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.397186.\tAccuracy: 0.844866\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.398312.\tAccuracy: 0.845647\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.397166.\tAccuracy: 0.843452\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.346114.\tAccuracy: 0.858482\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.346663.\tAccuracy: 0.862723\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.341573.\tAccuracy: 0.865253\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.304372.\tAccuracy: 0.880580\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.299026.\tAccuracy: 0.885603\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.297232.\tAccuracy: 0.886161\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.260365.\tAccuracy: 0.896429\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.257276.\tAccuracy: 0.900446\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.255659.\tAccuracy: 0.900446\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.240935.\tAccuracy: 0.902902\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.231100.\tAccuracy: 0.911272\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.227897.\tAccuracy: 0.912351\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.212308.\tAccuracy: 0.921205\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.206466.\tAccuracy: 0.922991\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.204198.\tAccuracy: 0.923512\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.183791.\tAccuracy: 0.927455\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.177966.\tAccuracy: 0.933594\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.174007.\tAccuracy: 0.936086\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.163488.\tAccuracy: 0.937723\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.162719.\tAccuracy: 0.938170\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.156691.\tAccuracy: 0.941741\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1134\n",
      "           1       0.71      0.82      0.76       194\n",
      "           2       0.80      0.66      0.72       363\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1691\n",
      "   macro avg       0.79      0.79      0.79      1691\n",
      "weighted avg       0.84      0.84      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.275259.\tAccuracy: 0.673214\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 1.027500.\tAccuracy: 0.702121\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.898289.\tAccuracy: 0.722173\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.494449.\tAccuracy: 0.808929\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.486608.\tAccuracy: 0.810379\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.482124.\tAccuracy: 0.811756\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.403469.\tAccuracy: 0.836830\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.402703.\tAccuracy: 0.841518\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.401292.\tAccuracy: 0.841443\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.353844.\tAccuracy: 0.863393\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.356396.\tAccuracy: 0.859598\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.354843.\tAccuracy: 0.859301\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.317295.\tAccuracy: 0.878125\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.311894.\tAccuracy: 0.882143\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.309529.\tAccuracy: 0.882440\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.276987.\tAccuracy: 0.892634\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.273480.\tAccuracy: 0.895647\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.271010.\tAccuracy: 0.893973\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.238518.\tAccuracy: 0.909821\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.237238.\tAccuracy: 0.911607\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.234725.\tAccuracy: 0.911235\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.210856.\tAccuracy: 0.916295\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.213338.\tAccuracy: 0.918750\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.207133.\tAccuracy: 0.920759\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.190459.\tAccuracy: 0.927009\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.186045.\tAccuracy: 0.928795\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.185797.\tAccuracy: 0.929390\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.170182.\tAccuracy: 0.936161\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.171337.\tAccuracy: 0.936272\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.166323.\tAccuracy: 0.937723\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1169\n",
      "           1       0.73      0.80      0.76       191\n",
      "           2       0.78      0.70      0.74       330\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1690\n",
      "   macro avg       0.80      0.80      0.80      1690\n",
      "weighted avg       0.85      0.85      0.85      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.134100.\tAccuracy: 0.668527\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.917433.\tAccuracy: 0.708036\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.819085.\tAccuracy: 0.727902\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.481352.\tAccuracy: 0.809821\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.479011.\tAccuracy: 0.814174\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.478295.\tAccuracy: 0.813988\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.412890.\tAccuracy: 0.834375\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.409066.\tAccuracy: 0.838393\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.405509.\tAccuracy: 0.837798\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.364783.\tAccuracy: 0.854018\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.361078.\tAccuracy: 0.855692\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.359097.\tAccuracy: 0.856994\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.316507.\tAccuracy: 0.871205\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.312158.\tAccuracy: 0.875000\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.312657.\tAccuracy: 0.875000\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.279952.\tAccuracy: 0.891964\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.276856.\tAccuracy: 0.894085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.276481.\tAccuracy: 0.892560\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.248141.\tAccuracy: 0.906027\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.250129.\tAccuracy: 0.903571\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.248791.\tAccuracy: 0.902976\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.216819.\tAccuracy: 0.914509\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.211454.\tAccuracy: 0.917634\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.212014.\tAccuracy: 0.916964\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.194787.\tAccuracy: 0.924330\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.193829.\tAccuracy: 0.928125\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.193040.\tAccuracy: 0.928869\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.165726.\tAccuracy: 0.937500\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.167136.\tAccuracy: 0.935603\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.165930.\tAccuracy: 0.935863\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      1150\n",
      "           1       0.73      0.82      0.77       209\n",
      "           2       0.78      0.63      0.70       331\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1690\n",
      "   macro avg       0.79      0.78      0.78      1690\n",
      "weighted avg       0.83      0.84      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.123290.\tAccuracy: 0.662054\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.925633.\tAccuracy: 0.702121\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.827379.\tAccuracy: 0.721429\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.499801.\tAccuracy: 0.804018\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.495707.\tAccuracy: 0.801674\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.491452.\tAccuracy: 0.803646\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.425532.\tAccuracy: 0.828348\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.422831.\tAccuracy: 0.833482\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.417653.\tAccuracy: 0.834301\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.386254.\tAccuracy: 0.845089\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.380236.\tAccuracy: 0.848103\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.377299.\tAccuracy: 0.849256\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.331157.\tAccuracy: 0.866964\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.328188.\tAccuracy: 0.873214\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.328198.\tAccuracy: 0.870908\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.296753.\tAccuracy: 0.878125\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.296144.\tAccuracy: 0.882589\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.291911.\tAccuracy: 0.883780\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.261692.\tAccuracy: 0.896205\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.260486.\tAccuracy: 0.894643\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.257065.\tAccuracy: 0.898735\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.230629.\tAccuracy: 0.910714\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.221900.\tAccuracy: 0.914062\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.218229.\tAccuracy: 0.914881\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.211034.\tAccuracy: 0.921652\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.202368.\tAccuracy: 0.922098\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.200836.\tAccuracy: 0.921949\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.176258.\tAccuracy: 0.936161\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.176041.\tAccuracy: 0.933371\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.176775.\tAccuracy: 0.933110\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      1119\n",
      "           1       0.74      0.72      0.73       209\n",
      "           2       0.83      0.65      0.73       362\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1690\n",
      "   macro avg       0.81      0.76      0.78      1690\n",
      "weighted avg       0.83      0.84      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.072463.\tAccuracy: 0.668973\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.895221.\tAccuracy: 0.708036\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.797830.\tAccuracy: 0.726265\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.496751.\tAccuracy: 0.800446\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.499556.\tAccuracy: 0.802121\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.492973.\tAccuracy: 0.803051\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.422382.\tAccuracy: 0.833259\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.428592.\tAccuracy: 0.830357\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.424487.\tAccuracy: 0.831771\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.375028.\tAccuracy: 0.845089\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.376617.\tAccuracy: 0.846540\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.373189.\tAccuracy: 0.849330\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.339910.\tAccuracy: 0.859821\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.330172.\tAccuracy: 0.866518\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.324966.\tAccuracy: 0.869420\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.301854.\tAccuracy: 0.880580\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.295808.\tAccuracy: 0.884263\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.292573.\tAccuracy: 0.884821\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.261236.\tAccuracy: 0.897545\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.264518.\tAccuracy: 0.896205\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.261167.\tAccuracy: 0.898363\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.224041.\tAccuracy: 0.912277\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.224910.\tAccuracy: 0.913616\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.226574.\tAccuracy: 0.910789\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.202579.\tAccuracy: 0.918973\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.202309.\tAccuracy: 0.921540\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.199623.\tAccuracy: 0.920908\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.180669.\tAccuracy: 0.931027\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.181676.\tAccuracy: 0.929464\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.181027.\tAccuracy: 0.930804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1166\n",
      "           1       0.78      0.81      0.80       194\n",
      "           2       0.85      0.68      0.76       330\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1690\n",
      "   macro avg       0.84      0.81      0.82      1690\n",
      "weighted avg       0.87      0.87      0.87      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.169500.\tAccuracy: 0.668527\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.941510.\tAccuracy: 0.705357\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.830977.\tAccuracy: 0.726265\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.498537.\tAccuracy: 0.796875\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.499253.\tAccuracy: 0.798326\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.492625.\tAccuracy: 0.803720\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.417117.\tAccuracy: 0.831027\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.416822.\tAccuracy: 0.833817\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.416657.\tAccuracy: 0.833110\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.362849.\tAccuracy: 0.851562\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.361338.\tAccuracy: 0.857254\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.357154.\tAccuracy: 0.859598\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.323852.\tAccuracy: 0.870536\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.326754.\tAccuracy: 0.869978\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.323313.\tAccuracy: 0.870833\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.286814.\tAccuracy: 0.883036\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.286723.\tAccuracy: 0.886384\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.281434.\tAccuracy: 0.888542\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.255230.\tAccuracy: 0.903125\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.254851.\tAccuracy: 0.903906\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.250613.\tAccuracy: 0.904464\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.216765.\tAccuracy: 0.919643\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.218598.\tAccuracy: 0.917857\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.215778.\tAccuracy: 0.919345\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.195261.\tAccuracy: 0.928795\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.187371.\tAccuracy: 0.929018\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.185596.\tAccuracy: 0.929688\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.174074.\tAccuracy: 0.934375\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.173227.\tAccuracy: 0.934040\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.169337.\tAccuracy: 0.935491\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1133\n",
      "           1       0.75      0.75      0.75       202\n",
      "           2       0.82      0.63      0.71       355\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1690\n",
      "   macro avg       0.81      0.76      0.78      1690\n",
      "weighted avg       0.83      0.83      0.83      1690\n",
      "\n",
      "weighted results are\n",
      "average precision is 0.836167\n",
      "average recall is 0.837447\n",
      "average f1 is 0.834883\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights glove --learn-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + Random Embedding\n",
    "\n",
    "__Command:__\n",
    "`!python lstm.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --initialize-weights random --learn-embeddings --epochs 10 --batch-size 128`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.802 (vs. 0.805)\n",
    "\n",
    "Recall(avg): 0.805 (vs. 0.804)\n",
    "\n",
    "F1-score(avg): 0.803 (vs. 0.804)\n",
    "\n",
    "__Reflection:__\n",
    "It checks out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 28\n",
      "3450 embedding missed\n",
      "Model variation is LSTM\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 28, 200)       3402800     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 28, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 50)            50200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             153         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 3)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,453,153\n",
      "Trainable params: 3,453,153\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "2019-10-06 17:32:28.973591: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.858460.\tAccuracy: 0.680357\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.798763.\tAccuracy: 0.687054\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.727406.\tAccuracy: 0.718750\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.427188.\tAccuracy: 0.836830\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.399550.\tAccuracy: 0.848549\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.374963.\tAccuracy: 0.858705\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.262969.\tAccuracy: 0.904687\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.248440.\tAccuracy: 0.911384\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.236819.\tAccuracy: 0.915848\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.185544.\tAccuracy: 0.939063\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.173451.\tAccuracy: 0.944085\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.165115.\tAccuracy: 0.946131\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.145078.\tAccuracy: 0.956027\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.133157.\tAccuracy: 0.957478\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.124984.\tAccuracy: 0.959598\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.110090.\tAccuracy: 0.966964\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.104431.\tAccuracy: 0.967969\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.098554.\tAccuracy: 0.969792\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.094814.\tAccuracy: 0.969643\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.089044.\tAccuracy: 0.971763\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.082373.\tAccuracy: 0.973140\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.079683.\tAccuracy: 0.975893\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.074953.\tAccuracy: 0.977567\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.069013.\tAccuracy: 0.979167\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.069735.\tAccuracy: 0.975670\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.066134.\tAccuracy: 0.977567\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.061480.\tAccuracy: 0.980134\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.065543.\tAccuracy: 0.978795\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.061311.\tAccuracy: 0.979353\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.055097.\tAccuracy: 0.981250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      1155\n",
      "           1       0.66      0.69      0.68       191\n",
      "           2       0.65      0.68      0.66       345\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1691\n",
      "   macro avg       0.72      0.73      0.73      1691\n",
      "weighted avg       0.79      0.79      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.815681.\tAccuracy: 0.680804\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.739484.\tAccuracy: 0.714063\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.658621.\tAccuracy: 0.744792\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.341420.\tAccuracy: 0.868304\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.321810.\tAccuracy: 0.875781\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.290037.\tAccuracy: 0.889955\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.184612.\tAccuracy: 0.936384\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.185468.\tAccuracy: 0.936272\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.171253.\tAccuracy: 0.941220\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.140224.\tAccuracy: 0.955134\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.133363.\tAccuracy: 0.955804\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.122034.\tAccuracy: 0.959970\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.114366.\tAccuracy: 0.962277\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.106454.\tAccuracy: 0.965067\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.097757.\tAccuracy: 0.967783\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.089948.\tAccuracy: 0.973214\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.083487.\tAccuracy: 0.974219\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.076901.\tAccuracy: 0.975446\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.074928.\tAccuracy: 0.975000\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.073991.\tAccuracy: 0.976674\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.067024.\tAccuracy: 0.978497\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.070412.\tAccuracy: 0.976116\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.064263.\tAccuracy: 0.977902\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.058448.\tAccuracy: 0.979315\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.055106.\tAccuracy: 0.982589\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.053282.\tAccuracy: 0.983259\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.049570.\tAccuracy: 0.984375\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.052529.\tAccuracy: 0.983259\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.047501.\tAccuracy: 0.985714\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.044064.\tAccuracy: 0.986161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      1176\n",
      "           1       0.70      0.60      0.65       187\n",
      "           2       0.65      0.62      0.64       328\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1691\n",
      "   macro avg       0.73      0.70      0.71      1691\n",
      "weighted avg       0.79      0.79      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.774357.\tAccuracy: 0.697321\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.670053.\tAccuracy: 0.738728\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.602227.\tAccuracy: 0.766667\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.319757.\tAccuracy: 0.878125\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.294923.\tAccuracy: 0.888393\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.276267.\tAccuracy: 0.897545\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.190230.\tAccuracy: 0.933036\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.181071.\tAccuracy: 0.935491\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.171013.\tAccuracy: 0.938914\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.142676.\tAccuracy: 0.951562\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.135272.\tAccuracy: 0.953683\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.127150.\tAccuracy: 0.956250\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.108542.\tAccuracy: 0.966518\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.107027.\tAccuracy: 0.965848\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.099356.\tAccuracy: 0.968676\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.086947.\tAccuracy: 0.972321\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.082729.\tAccuracy: 0.973326\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.078886.\tAccuracy: 0.973661\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.077156.\tAccuracy: 0.975000\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.070580.\tAccuracy: 0.977232\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.068225.\tAccuracy: 0.977753\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.064786.\tAccuracy: 0.979018\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.061549.\tAccuracy: 0.980246\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.057180.\tAccuracy: 0.981250\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.060924.\tAccuracy: 0.980134\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.055786.\tAccuracy: 0.981473\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.050170.\tAccuracy: 0.983557\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.051498.\tAccuracy: 0.981696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.050759.\tAccuracy: 0.983036\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.046350.\tAccuracy: 0.984226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1155\n",
      "           1       0.74      0.56      0.64       205\n",
      "           2       0.69      0.61      0.65       331\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1691\n",
      "   macro avg       0.75      0.69      0.72      1691\n",
      "weighted avg       0.79      0.80      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.786997.\tAccuracy: 0.669643\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.672668.\tAccuracy: 0.725000\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.606243.\tAccuracy: 0.753646\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.308503.\tAccuracy: 0.880134\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.284786.\tAccuracy: 0.892746\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.265689.\tAccuracy: 0.899777\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.180018.\tAccuracy: 0.938393\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.172317.\tAccuracy: 0.939955\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.162401.\tAccuracy: 0.942560\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.130797.\tAccuracy: 0.959598\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.127312.\tAccuracy: 0.958482\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.119339.\tAccuracy: 0.960119\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.102381.\tAccuracy: 0.967411\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.101036.\tAccuracy: 0.967187\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.096919.\tAccuracy: 0.968229\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.084606.\tAccuracy: 0.972545\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.083971.\tAccuracy: 0.971987\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.079921.\tAccuracy: 0.972693\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.068683.\tAccuracy: 0.975893\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.066278.\tAccuracy: 0.978013\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.063311.\tAccuracy: 0.979315\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.066107.\tAccuracy: 0.978125\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.063271.\tAccuracy: 0.980357\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.058205.\tAccuracy: 0.981027\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.059507.\tAccuracy: 0.980134\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.055493.\tAccuracy: 0.982031\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.049920.\tAccuracy: 0.983705\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.060802.\tAccuracy: 0.979911\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.054477.\tAccuracy: 0.983036\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.049179.\tAccuracy: 0.984598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1142\n",
      "           1       0.69      0.62      0.66       194\n",
      "           2       0.75      0.61      0.67       355\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1691\n",
      "   macro avg       0.76      0.71      0.73      1691\n",
      "weighted avg       0.80      0.80      0.80      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.801733.\tAccuracy: 0.686830\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.700967.\tAccuracy: 0.728348\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.632896.\tAccuracy: 0.754315\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.321273.\tAccuracy: 0.877455\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.306664.\tAccuracy: 0.885491\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.291301.\tAccuracy: 0.891815\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.195177.\tAccuracy: 0.932143\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.191269.\tAccuracy: 0.933371\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.182729.\tAccuracy: 0.936310\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.144326.\tAccuracy: 0.950000\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.137884.\tAccuracy: 0.953237\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.128890.\tAccuracy: 0.955729\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.113310.\tAccuracy: 0.962723\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.109112.\tAccuracy: 0.964174\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.103446.\tAccuracy: 0.965030\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.095370.\tAccuracy: 0.970759\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.092369.\tAccuracy: 0.970536\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.086962.\tAccuracy: 0.972545\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.085906.\tAccuracy: 0.974554\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.078851.\tAccuracy: 0.974330\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.073370.\tAccuracy: 0.976711\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.070730.\tAccuracy: 0.977009\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.065425.\tAccuracy: 0.978013\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.060929.\tAccuracy: 0.980060\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.057995.\tAccuracy: 0.981473\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.055234.\tAccuracy: 0.983371\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.051381.\tAccuracy: 0.984598\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.054972.\tAccuracy: 0.978571\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.053544.\tAccuracy: 0.980469\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.050155.\tAccuracy: 0.982738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      1134\n",
      "           1       0.61      0.59      0.60       194\n",
      "           2       0.74      0.64      0.69       363\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1691\n",
      "   macro avg       0.73      0.70      0.71      1691\n",
      "weighted avg       0.78      0.79      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.806325.\tAccuracy: 0.672768\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.702306.\tAccuracy: 0.716741\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.635809.\tAccuracy: 0.746131\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.336274.\tAccuracy: 0.869643\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.316990.\tAccuracy: 0.879129\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.299858.\tAccuracy: 0.886756\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.206868.\tAccuracy: 0.926562\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.200678.\tAccuracy: 0.928683\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.191662.\tAccuracy: 0.931027\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.155148.\tAccuracy: 0.947991\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.152305.\tAccuracy: 0.948884\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.143395.\tAccuracy: 0.952083\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.126477.\tAccuracy: 0.956250\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.120005.\tAccuracy: 0.960268\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.112942.\tAccuracy: 0.962128\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.101596.\tAccuracy: 0.966964\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.097510.\tAccuracy: 0.968304\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.091875.\tAccuracy: 0.970610\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.079168.\tAccuracy: 0.972545\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.078689.\tAccuracy: 0.973549\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.075045.\tAccuracy: 0.975223\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.068398.\tAccuracy: 0.975223\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.066797.\tAccuracy: 0.977344\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.064058.\tAccuracy: 0.979613\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.065913.\tAccuracy: 0.979911\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.058653.\tAccuracy: 0.982143\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.054980.\tAccuracy: 0.983259\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.056844.\tAccuracy: 0.981473\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.055332.\tAccuracy: 0.982478\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.051865.\tAccuracy: 0.982812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      1169\n",
      "           1       0.69      0.64      0.66       191\n",
      "           2       0.72      0.69      0.70       330\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.76      0.74      0.75      1690\n",
      "weighted avg       0.81      0.82      0.81      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.875464.\tAccuracy: 0.646205\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.751323.\tAccuracy: 0.697991\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.678378.\tAccuracy: 0.729167\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.347332.\tAccuracy: 0.863393\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.326892.\tAccuracy: 0.876339\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.309836.\tAccuracy: 0.882515\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.218423.\tAccuracy: 0.917634\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.211905.\tAccuracy: 0.920424\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.200309.\tAccuracy: 0.925670\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.164255.\tAccuracy: 0.943750\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.155625.\tAccuracy: 0.945312\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.148051.\tAccuracy: 0.947470\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.118426.\tAccuracy: 0.958929\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.118169.\tAccuracy: 0.957701\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.112563.\tAccuracy: 0.959747\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.095526.\tAccuracy: 0.968973\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.093499.\tAccuracy: 0.969308\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.090891.\tAccuracy: 0.969271\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.088224.\tAccuracy: 0.968973\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.084305.\tAccuracy: 0.971652\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.078754.\tAccuracy: 0.973810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.073140.\tAccuracy: 0.975000\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.072192.\tAccuracy: 0.975000\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.069100.\tAccuracy: 0.976042\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.064909.\tAccuracy: 0.980580\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.063399.\tAccuracy: 0.981250\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.058970.\tAccuracy: 0.982143\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.050986.\tAccuracy: 0.980134\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.051251.\tAccuracy: 0.981585\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.049634.\tAccuracy: 0.982068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      1150\n",
      "           1       0.74      0.68      0.71       209\n",
      "           2       0.66      0.65      0.66       331\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1690\n",
      "   macro avg       0.75      0.73      0.74      1690\n",
      "weighted avg       0.80      0.80      0.80      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.877204.\tAccuracy: 0.653795\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.754537.\tAccuracy: 0.701228\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.684961.\tAccuracy: 0.731250\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.352723.\tAccuracy: 0.866295\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.334280.\tAccuracy: 0.873884\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.320839.\tAccuracy: 0.878646\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.224752.\tAccuracy: 0.917411\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.221776.\tAccuracy: 0.917411\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.210585.\tAccuracy: 0.921652\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.162558.\tAccuracy: 0.940625\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.161289.\tAccuracy: 0.940960\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.151397.\tAccuracy: 0.945238\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.125223.\tAccuracy: 0.959821\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.121597.\tAccuracy: 0.959821\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.119384.\tAccuracy: 0.961086\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.103628.\tAccuracy: 0.967857\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.101324.\tAccuracy: 0.966741\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.097035.\tAccuracy: 0.967708\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.087974.\tAccuracy: 0.972991\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.085617.\tAccuracy: 0.972545\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.083636.\tAccuracy: 0.971949\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.084825.\tAccuracy: 0.971429\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.081187.\tAccuracy: 0.972433\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.074453.\tAccuracy: 0.975000\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.068010.\tAccuracy: 0.976562\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.066730.\tAccuracy: 0.976562\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.064828.\tAccuracy: 0.977009\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.059974.\tAccuracy: 0.978795\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.057917.\tAccuracy: 0.980246\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.054024.\tAccuracy: 0.982292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1119\n",
      "           1       0.78      0.66      0.72       209\n",
      "           2       0.73      0.67      0.70       362\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.79      0.74      0.76      1690\n",
      "weighted avg       0.82      0.82      0.82      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.005200.\tAccuracy: 0.596875\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.862715.\tAccuracy: 0.646205\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.774815.\tAccuracy: 0.681696\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.402140.\tAccuracy: 0.843527\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.388043.\tAccuracy: 0.850000\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.365437.\tAccuracy: 0.858482\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.257381.\tAccuracy: 0.910045\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.244916.\tAccuracy: 0.912500\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.229909.\tAccuracy: 0.916592\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.175415.\tAccuracy: 0.933705\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.171305.\tAccuracy: 0.937388\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.165138.\tAccuracy: 0.940104\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.140185.\tAccuracy: 0.953348\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.139568.\tAccuracy: 0.952790\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.130403.\tAccuracy: 0.954241\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.113037.\tAccuracy: 0.961830\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.114901.\tAccuracy: 0.960826\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.109371.\tAccuracy: 0.962277\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.097661.\tAccuracy: 0.967187\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.099708.\tAccuracy: 0.964621\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.092464.\tAccuracy: 0.966964\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.081786.\tAccuracy: 0.969866\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.077411.\tAccuracy: 0.972545\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.071533.\tAccuracy: 0.974479\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.077832.\tAccuracy: 0.972098\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.074480.\tAccuracy: 0.973661\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.070757.\tAccuracy: 0.975000\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.069604.\tAccuracy: 0.976116\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.063019.\tAccuracy: 0.977455\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.060470.\tAccuracy: 0.978348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1166\n",
      "           1       0.77      0.71      0.74       194\n",
      "           2       0.72      0.70      0.71       330\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1690\n",
      "   macro avg       0.79      0.77      0.78      1690\n",
      "weighted avg       0.83      0.83      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.881640.\tAccuracy: 0.665179\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.766313.\tAccuracy: 0.699107\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.690035.\tAccuracy: 0.729390\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.372641.\tAccuracy: 0.853571\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.360190.\tAccuracy: 0.861272\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.340033.\tAccuracy: 0.869271\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.238942.\tAccuracy: 0.910268\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.231299.\tAccuracy: 0.914062\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.222617.\tAccuracy: 0.918155\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.177060.\tAccuracy: 0.934821\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.171593.\tAccuracy: 0.939063\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.164136.\tAccuracy: 0.940551\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.135202.\tAccuracy: 0.955134\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.135061.\tAccuracy: 0.954353\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.131268.\tAccuracy: 0.954613\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.105638.\tAccuracy: 0.964509\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.107482.\tAccuracy: 0.964732\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.102039.\tAccuracy: 0.965997\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.099551.\tAccuracy: 0.968973\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.095729.\tAccuracy: 0.968527\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.091874.\tAccuracy: 0.969196\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.093594.\tAccuracy: 0.969196\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.086261.\tAccuracy: 0.971317\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.079968.\tAccuracy: 0.973437\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.076991.\tAccuracy: 0.972545\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.075970.\tAccuracy: 0.973326\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.070562.\tAccuracy: 0.975893\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.060271.\tAccuracy: 0.979911\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.062322.\tAccuracy: 0.978795\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.059662.\tAccuracy: 0.979167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      1133\n",
      "           1       0.71      0.71      0.71       202\n",
      "           2       0.69      0.68      0.69       355\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1690\n",
      "   macro avg       0.75      0.75      0.75      1690\n",
      "weighted avg       0.80      0.80      0.80      1690\n",
      "\n",
      "macro results are\n",
      "average precision is 0.802283\n",
      "average recall is 0.804735\n",
      "average f1 is 0.802594\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "!python lstm.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --initialize-weights random --learn-embeddings --epochs 10 --batch-size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + GloVe\n",
    "\n",
    "__Command:__\n",
    "`!python lstm.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --initialize-weights glove --learn-embeddings --epochs 10 --batch-size 128`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.834 (vs. 0.807)\n",
    "\n",
    "Recall(avg): 0.835 (vs. 0.809)\n",
    "\n",
    "F1-score(avg): 0.836 (vs. 0.808)\n",
    "\n",
    "__Reflection:__\n",
    "The results are much better than reported on the pattern. Note that the improvement with respect to the random initiliazation is similar to the one observed for CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 28\n",
      "3450 embedding missed\n",
      "Model variation is LSTM\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 28, 200)       3402800     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 28, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 50)            50200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             153         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 3)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,453,153\n",
      "Trainable params: 3,453,153\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "2019-10-06 20:30:52.732313: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.845858.\tAccuracy: 0.636830\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.757362.\tAccuracy: 0.678683\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.694445.\tAccuracy: 0.709375\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.502235.\tAccuracy: 0.804241\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.492079.\tAccuracy: 0.806696\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.480763.\tAccuracy: 0.811682\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.412048.\tAccuracy: 0.840179\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.402355.\tAccuracy: 0.843080\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.393095.\tAccuracy: 0.847173\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.347241.\tAccuracy: 0.865179\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.337564.\tAccuracy: 0.870982\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.327952.\tAccuracy: 0.874851\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.286593.\tAccuracy: 0.887500\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.277238.\tAccuracy: 0.894085\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.269105.\tAccuracy: 0.896205\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.238719.\tAccuracy: 0.912946\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.232280.\tAccuracy: 0.915402\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.227817.\tAccuracy: 0.915551\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.199712.\tAccuracy: 0.929241\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.197807.\tAccuracy: 0.930804\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.192502.\tAccuracy: 0.930804\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.186440.\tAccuracy: 0.933705\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.178186.\tAccuracy: 0.935937\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.169627.\tAccuracy: 0.938244\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.160376.\tAccuracy: 0.942857\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.154355.\tAccuracy: 0.945871\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.146729.\tAccuracy: 0.948140\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.142785.\tAccuracy: 0.949554\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.138864.\tAccuracy: 0.951562\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.130208.\tAccuracy: 0.954688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      1155\n",
      "           1       0.69      0.76      0.72       191\n",
      "           2       0.76      0.69      0.72       345\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.78      0.78      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.820675.\tAccuracy: 0.646875\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.731441.\tAccuracy: 0.689063\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.668883.\tAccuracy: 0.722024\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.473469.\tAccuracy: 0.810714\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.465809.\tAccuracy: 0.815290\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.450647.\tAccuracy: 0.820833\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.397676.\tAccuracy: 0.842187\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.383463.\tAccuracy: 0.850112\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.368402.\tAccuracy: 0.856920\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.333982.\tAccuracy: 0.869420\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.318933.\tAccuracy: 0.877232\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.310265.\tAccuracy: 0.881250\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.279625.\tAccuracy: 0.892634\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.276960.\tAccuracy: 0.896317\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.265724.\tAccuracy: 0.900074\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.246491.\tAccuracy: 0.908036\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.234667.\tAccuracy: 0.913616\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.224851.\tAccuracy: 0.916964\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.205880.\tAccuracy: 0.924777\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.200092.\tAccuracy: 0.927902\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.189782.\tAccuracy: 0.931101\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.183490.\tAccuracy: 0.938393\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.176187.\tAccuracy: 0.940513\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.167682.\tAccuracy: 0.941741\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.153401.\tAccuracy: 0.945759\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.150670.\tAccuracy: 0.946540\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.145396.\tAccuracy: 0.947619\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.140345.\tAccuracy: 0.954464\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.133119.\tAccuracy: 0.955022\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.127292.\tAccuracy: 0.955878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      1176\n",
      "           1       0.68      0.70      0.69       187\n",
      "           2       0.71      0.66      0.68       328\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1691\n",
      "   macro avg       0.75      0.74      0.75      1691\n",
      "weighted avg       0.81      0.81      0.81      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.893074.\tAccuracy: 0.624777\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.770878.\tAccuracy: 0.678460\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.703210.\tAccuracy: 0.708036\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.486447.\tAccuracy: 0.806696\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.480103.\tAccuracy: 0.809821\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.467200.\tAccuracy: 0.814137\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.408243.\tAccuracy: 0.839955\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.398619.\tAccuracy: 0.846094\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.384404.\tAccuracy: 0.850149\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.332308.\tAccuracy: 0.872991\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.333620.\tAccuracy: 0.875670\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.328392.\tAccuracy: 0.877009\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.285078.\tAccuracy: 0.890848\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.282417.\tAccuracy: 0.892969\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.274873.\tAccuracy: 0.895312\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.244663.\tAccuracy: 0.906250\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.243425.\tAccuracy: 0.909375\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.235463.\tAccuracy: 0.913393\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.206958.\tAccuracy: 0.927902\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.205249.\tAccuracy: 0.925781\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.198654.\tAccuracy: 0.927158\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.180746.\tAccuracy: 0.934598\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.177188.\tAccuracy: 0.937054\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.171532.\tAccuracy: 0.937649\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.161561.\tAccuracy: 0.942634\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.158551.\tAccuracy: 0.944643\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.152619.\tAccuracy: 0.945685\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.138982.\tAccuracy: 0.952232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.138503.\tAccuracy: 0.952121\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.133872.\tAccuracy: 0.951637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1155\n",
      "           1       0.71      0.78      0.74       205\n",
      "           2       0.75      0.66      0.70       331\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.78      0.78      0.78      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.866980.\tAccuracy: 0.646652\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.761629.\tAccuracy: 0.688504\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.700121.\tAccuracy: 0.715179\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.489990.\tAccuracy: 0.803571\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.480168.\tAccuracy: 0.809152\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.468053.\tAccuracy: 0.813318\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.400154.\tAccuracy: 0.843527\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.393794.\tAccuracy: 0.848326\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.387711.\tAccuracy: 0.852083\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.329171.\tAccuracy: 0.872545\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.324161.\tAccuracy: 0.878348\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.314899.\tAccuracy: 0.882887\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.274288.\tAccuracy: 0.894643\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.273186.\tAccuracy: 0.896429\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.265781.\tAccuracy: 0.899256\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.232654.\tAccuracy: 0.913839\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.230754.\tAccuracy: 0.914397\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.225121.\tAccuracy: 0.917411\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.196288.\tAccuracy: 0.925446\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.194392.\tAccuracy: 0.927344\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.192836.\tAccuracy: 0.928646\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.177855.\tAccuracy: 0.938170\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.174425.\tAccuracy: 0.938281\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.168371.\tAccuracy: 0.939881\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.149741.\tAccuracy: 0.946205\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.151226.\tAccuracy: 0.944420\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.146989.\tAccuracy: 0.945164\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.134744.\tAccuracy: 0.950446\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.135180.\tAccuracy: 0.949554\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.128487.\tAccuracy: 0.951860\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1142\n",
      "           1       0.73      0.71      0.72       194\n",
      "           2       0.78      0.69      0.73       355\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.79      0.76      0.78      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.845210.\tAccuracy: 0.639955\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.745693.\tAccuracy: 0.690625\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.688292.\tAccuracy: 0.717857\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.497626.\tAccuracy: 0.800000\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.491503.\tAccuracy: 0.804576\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.476653.\tAccuracy: 0.809598\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.406375.\tAccuracy: 0.843750\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.402892.\tAccuracy: 0.847879\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.392217.\tAccuracy: 0.848810\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.343044.\tAccuracy: 0.862277\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.341793.\tAccuracy: 0.867076\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.331840.\tAccuracy: 0.871429\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.284108.\tAccuracy: 0.894420\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.283985.\tAccuracy: 0.894531\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.277810.\tAccuracy: 0.895685\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.248747.\tAccuracy: 0.912946\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.250927.\tAccuracy: 0.912388\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.242489.\tAccuracy: 0.913765\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.218819.\tAccuracy: 0.916295\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.212696.\tAccuracy: 0.921429\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.209592.\tAccuracy: 0.921131\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.189438.\tAccuracy: 0.929464\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.191612.\tAccuracy: 0.930915\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.183436.\tAccuracy: 0.932143\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.166204.\tAccuracy: 0.940402\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.162746.\tAccuracy: 0.944085\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.158719.\tAccuracy: 0.943973\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.148881.\tAccuracy: 0.944866\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.150040.\tAccuracy: 0.946875\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.143025.\tAccuracy: 0.949628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      1134\n",
      "           1       0.70      0.79      0.74       194\n",
      "           2       0.79      0.71      0.74       363\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1691\n",
      "   macro avg       0.79      0.79      0.79      1691\n",
      "weighted avg       0.84      0.84      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.824667.\tAccuracy: 0.651786\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.748123.\tAccuracy: 0.684821\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.695443.\tAccuracy: 0.709449\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.500310.\tAccuracy: 0.802679\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.491369.\tAccuracy: 0.807254\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.478986.\tAccuracy: 0.812054\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.410794.\tAccuracy: 0.837500\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.403531.\tAccuracy: 0.840737\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.395056.\tAccuracy: 0.845238\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.344823.\tAccuracy: 0.868750\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.340568.\tAccuracy: 0.870089\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.333221.\tAccuracy: 0.872768\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.283580.\tAccuracy: 0.884152\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.281543.\tAccuracy: 0.889286\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.275528.\tAccuracy: 0.892560\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.243290.\tAccuracy: 0.904464\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.248372.\tAccuracy: 0.905692\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.242393.\tAccuracy: 0.907813\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.209643.\tAccuracy: 0.921652\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.207412.\tAccuracy: 0.924330\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.203331.\tAccuracy: 0.925595\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.179104.\tAccuracy: 0.935268\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.179895.\tAccuracy: 0.934821\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.176038.\tAccuracy: 0.936458\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.161983.\tAccuracy: 0.944643\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.156061.\tAccuracy: 0.945424\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.153199.\tAccuracy: 0.945461\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.146628.\tAccuracy: 0.946652\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.143178.\tAccuracy: 0.946652\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.137963.\tAccuracy: 0.948289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1169\n",
      "           1       0.73      0.68      0.70       191\n",
      "           2       0.80      0.71      0.75       330\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1690\n",
      "   macro avg       0.80      0.77      0.78      1690\n",
      "weighted avg       0.85      0.85      0.85      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.884066.\tAccuracy: 0.642634\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.770947.\tAccuracy: 0.686384\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.709191.\tAccuracy: 0.709747\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.487013.\tAccuracy: 0.804911\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.482770.\tAccuracy: 0.808147\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.472045.\tAccuracy: 0.811979\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.400122.\tAccuracy: 0.842411\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.395806.\tAccuracy: 0.844531\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.384048.\tAccuracy: 0.849033\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.336978.\tAccuracy: 0.864732\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.335000.\tAccuracy: 0.869531\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.326239.\tAccuracy: 0.871429\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.281040.\tAccuracy: 0.895982\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.281486.\tAccuracy: 0.895312\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.276656.\tAccuracy: 0.896354\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.249768.\tAccuracy: 0.900000\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.242321.\tAccuracy: 0.906920\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.237285.\tAccuracy: 0.909747\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.210148.\tAccuracy: 0.922991\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.214043.\tAccuracy: 0.922768\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.208806.\tAccuracy: 0.922098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.190188.\tAccuracy: 0.930580\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.191058.\tAccuracy: 0.929464\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.185370.\tAccuracy: 0.931399\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.167182.\tAccuracy: 0.942187\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.165609.\tAccuracy: 0.941295\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.161623.\tAccuracy: 0.942113\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.148983.\tAccuracy: 0.949330\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.145385.\tAccuracy: 0.948772\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.142125.\tAccuracy: 0.950298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      1150\n",
      "           1       0.71      0.78      0.75       209\n",
      "           2       0.76      0.63      0.69       331\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.78      0.77      0.77      1690\n",
      "weighted avg       0.82      0.82      0.82      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.839351.\tAccuracy: 0.659598\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.737023.\tAccuracy: 0.700446\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.687055.\tAccuracy: 0.722693\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.500200.\tAccuracy: 0.799330\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.489638.\tAccuracy: 0.806808\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.479958.\tAccuracy: 0.811533\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.417296.\tAccuracy: 0.834821\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.404970.\tAccuracy: 0.839844\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.396131.\tAccuracy: 0.843973\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.339972.\tAccuracy: 0.867411\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.338764.\tAccuracy: 0.868750\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.334698.\tAccuracy: 0.870759\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.293300.\tAccuracy: 0.889509\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.290146.\tAccuracy: 0.892634\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.289298.\tAccuracy: 0.892262\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.252874.\tAccuracy: 0.903795\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.247092.\tAccuracy: 0.908259\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.245083.\tAccuracy: 0.907961\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.231317.\tAccuracy: 0.916518\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.224880.\tAccuracy: 0.919085\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.220740.\tAccuracy: 0.920015\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.201939.\tAccuracy: 0.927455\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.189452.\tAccuracy: 0.931920\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.184871.\tAccuracy: 0.932217\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.175242.\tAccuracy: 0.937054\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.168819.\tAccuracy: 0.938504\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.166561.\tAccuracy: 0.938765\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.152328.\tAccuracy: 0.945312\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.154095.\tAccuracy: 0.944308\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.149006.\tAccuracy: 0.946280\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      1119\n",
      "           1       0.74      0.77      0.76       209\n",
      "           2       0.77      0.73      0.75       362\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1690\n",
      "   macro avg       0.80      0.80      0.80      1690\n",
      "weighted avg       0.84      0.84      0.84      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.965048.\tAccuracy: 0.601339\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.827995.\tAccuracy: 0.655134\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.756727.\tAccuracy: 0.687351\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.519576.\tAccuracy: 0.795759\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.509667.\tAccuracy: 0.800112\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.496659.\tAccuracy: 0.801339\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.421560.\tAccuracy: 0.826786\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.410893.\tAccuracy: 0.834040\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.405386.\tAccuracy: 0.837426\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.357324.\tAccuracy: 0.857589\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.351242.\tAccuracy: 0.861719\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.342073.\tAccuracy: 0.866071\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.307748.\tAccuracy: 0.882143\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.305775.\tAccuracy: 0.885268\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.299596.\tAccuracy: 0.886384\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.264051.\tAccuracy: 0.900223\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.262353.\tAccuracy: 0.900893\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.256226.\tAccuracy: 0.902827\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.234350.\tAccuracy: 0.911384\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.233209.\tAccuracy: 0.913170\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.226856.\tAccuracy: 0.915551\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.218768.\tAccuracy: 0.920759\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.207772.\tAccuracy: 0.924442\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.195952.\tAccuracy: 0.926860\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.182102.\tAccuracy: 0.933929\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.180223.\tAccuracy: 0.934598\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.173594.\tAccuracy: 0.935937\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.169238.\tAccuracy: 0.942634\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.167051.\tAccuracy: 0.942187\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.158477.\tAccuracy: 0.945238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1166\n",
      "           1       0.78      0.77      0.78       194\n",
      "           2       0.84      0.74      0.79       330\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1690\n",
      "   macro avg       0.84      0.81      0.82      1690\n",
      "weighted avg       0.87      0.87      0.87      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.866933.\tAccuracy: 0.645536\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.771063.\tAccuracy: 0.677790\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.716196.\tAccuracy: 0.701042\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.510574.\tAccuracy: 0.799330\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.505971.\tAccuracy: 0.799442\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.495399.\tAccuracy: 0.801488\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.418145.\tAccuracy: 0.828348\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.415335.\tAccuracy: 0.829241\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.409474.\tAccuracy: 0.833110\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.364163.\tAccuracy: 0.855804\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.356958.\tAccuracy: 0.858371\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.349674.\tAccuracy: 0.860045\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.311510.\tAccuracy: 0.876786\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.302330.\tAccuracy: 0.881585\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.299809.\tAccuracy: 0.884673\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.265595.\tAccuracy: 0.898438\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.265323.\tAccuracy: 0.897098\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.259167.\tAccuracy: 0.899777\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.232947.\tAccuracy: 0.914732\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.230996.\tAccuracy: 0.914286\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.226700.\tAccuracy: 0.915551\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.211152.\tAccuracy: 0.917634\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.205768.\tAccuracy: 0.923103\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.199692.\tAccuracy: 0.924851\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.180516.\tAccuracy: 0.932589\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.176753.\tAccuracy: 0.932701\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.173279.\tAccuracy: 0.934375\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.164803.\tAccuracy: 0.943973\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.164069.\tAccuracy: 0.942076\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.157372.\tAccuracy: 0.943229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      1133\n",
      "           1       0.73      0.75      0.74       202\n",
      "           2       0.75      0.68      0.71       355\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.78      0.77      0.78      1690\n",
      "weighted avg       0.82      0.82      0.82      1690\n",
      "\n",
      "macro results are\n",
      "average precision is 0.833672\n",
      "average recall is 0.834903\n",
      "average f1 is 0.833588\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "!python lstm.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --initialize-weights glove --learn-embeddings --epochs 10 --batch-size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - DNNs + GBDT Classifier\n",
    "---\n",
    "### CNN + GloVe + GBDT\n",
    "__Command:__\n",
    "`!python nn_classifier.py gradient_boosting cnn_glove.h5`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.869 (vs. 0.864)\n",
    "\n",
    "Recall(avg): 0.869 (vs. 0.864)\n",
    "\n",
    "F1-score(avg): 0.864 (vs. 0.864)\n",
    "\n",
    "__Reflection:__\n",
    "It checks out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Embedding Dimension: 200\n",
      "2019-10-06 21:48:48.024133: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Model Type: gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 11.2min finished\n",
      "Precision(avg): 0.869 (+/- 0.011)\n",
      "Recall(avg): 0.869 (+/- 0.011)\n",
      "F1-score(avg): 0.864 (+/- 0.012)\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py gradient_boosting cnn_glove.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + Random Embedding + GBDT\n",
    "__Command:__\n",
    "`!python nn_classifier.py gradient_boosting cnn_random.h5`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.913 (vs. 0.864)\n",
    "\n",
    "Recall(avg): 0.913 (vs. 0.864)\n",
    "\n",
    "F1-score(avg): 0.912 (vs. 0.864)\n",
    "\n",
    "__Reflection:__ The results I obtain are much higher than those reported by the paper. It is also strange that they report the same exact results for both the embedding initialization with GloVe and at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Embedding Dimension: 200\n",
      "2019-10-06 21:38:10.343954: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Model Type: gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 10.4min finished\n",
      "Precision(avg): 0.913 (+/- 0.013)\n",
      "Recall(avg): 0.913 (+/- 0.013)\n",
      "F1-score(avg): 0.912 (+/- 0.013)\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py gradient_boosting cnn_random.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + GloVe + GBDT\n",
    "__Command:__\n",
    "`!python nn_classifier.py gradient_boosting lstm_glove.h5`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.865 (vs. 0.849)\n",
    "\n",
    "Recall(avg): 0.864  (vs. 0.848)\n",
    "\n",
    "F1-score(avg): 0.859 (vs. 0.848)\n",
    "\n",
    "__Reflection:__ The results I obtained are slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Embedding Dimension: 200\n",
      "2019-10-06 22:11:47.580129: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Model Type: gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 11.3min finished\n",
      "Precision(avg): 0.865 (+/- 0.013)\n",
      "Recall(avg): 0.864 (+/- 0.012)\n",
      "F1-score(avg): 0.859 (+/- 0.013)\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py gradient_boosting lstm_glove.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + Random Embedding + GBDT\n",
    "__Command:__\n",
    "`!python nn_classifier.py gradient_boosting lstm_random.h5`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.934 (vs. 0.930)\n",
    "\n",
    "Recall(avg): 0.934 (vs. 0.930)\n",
    "\n",
    "F1-score(avg): 0.934 (vs. 0.930)\n",
    "\n",
    "__Reflection:__ It checks out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Embedding Dimension: 200\n",
      "2019-10-06 22:00:13.692928: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Model Type: gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 11.3min finished\n",
      "Precision(avg): 0.934 (+/- 0.012)\n",
      "Recall(avg): 0.934 (+/- 0.012)\n",
      "F1-score(avg): 0.933 (+/- 0.012)\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py gradient_boosting lstm_random.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
