{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication Summary\n",
    "\n",
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Balanced SVM\n",
    "\n",
    "__Command:__\n",
    "`!python tfidf.py -m tfidf_svm --kernel rbf --class_weight balanced --max_ngram 3 --jobs -2 --seed 42 --tokenizer glove`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.823. (vs. 0.816)\n",
    "\n",
    "Recall(avg): 0.826 (vs. 0.816)\n",
    "\n",
    "F1-score(avg): 0.823 (vs. 0.816)\n",
    "\n",
    "__Reflection:__ Looks good!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_svm\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.6min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.6min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.7min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.2min\n",
      "[CV] ................................................. , total= 3.3min\n",
      "[CV] ................................................. , total= 3.7min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 24.7min finished\n",
      "Precision(avg): 0.823 (+/- 0.019)\n",
      "Recall(avg): 0.826 (+/- 0.019)\n",
      "F1-score(avg): 0.823 (+/- 0.019)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_svm --kernel rbf --class_weight balanced --max_ngram 3 --jobs -2 --seed 42 --tokenizer glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + GBDT\n",
    "\n",
    "__Command:__\n",
    "`!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.826 (vs. 0.819)\n",
    "\n",
    "Recall(avg): 0.817 (vs. 0.807)\n",
    "\n",
    "F1-score(avg): 0.801 (vs. 0.813)\n",
    "\n",
    "__Reflection:__\n",
    "Close enough. Notice that the second try enables inverse-document-frequency reweighting (i.e., `--use-inverse-doc-freq`), which does not affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.4min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.7min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV] ................................................. , total=14.2min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 59.7min finished\n",
      "Precision(avg): 0.826 (+/- 0.014)\n",
      "Recall(avg): 0.817 (+/- 0.013)\n",
      "F1-score(avg): 0.801 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-ngram-length: 3\n",
      "Found 16907 texts. (samples)\n",
      "Model Type: tfidf_gradient_boosting\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.3min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=16.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=14.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=15.0min\n",
      "[CV] ................................................. , total=15.1min\n",
      "[CV] ................................................. , total=14.2min\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 59.6min finished\n",
      "Precision(avg): 0.825 (+/- 0.013)\n",
      "Recall(avg): 0.816 (+/- 0.013)\n",
      "F1-score(avg): 0.800 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python tfidf.py -m tfidf_gradient_boosting --max_ngram 3 --loss deviance --estimators 100 --jobs -2 --seed 42 --tokenizer glove --use-inverse-doc-freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoWV + Balanced SVM \n",
    "\n",
    "__Command:__\n",
    "`!python BoWV.py -m svm --kernel rbf --class_weight balanced --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.758 (vs. 0.791)\n",
    "\n",
    "Recall(avg): 0.692 (vs. 0.788)\n",
    "\n",
    "F1-score(avg): 0.705 (0.789)\n",
    "\n",
    "__Reflection:__ SVMs are very sensitive to the choice of hyperparameters. We see that the default `rbf` kernel has a performance much worse than reported by the paper. Howeover, since the same SVM performs well in the tf-idf model and the gradient boosting estimator also underperforms in the BoWV model, we have reason to believe something is wrong with the BoWV model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "GloVe model loaded successfully.\n",
      "Tweets selected: 16905\n",
      "Features and labels loaded from pickled files.\n",
      "Model Type: svm\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 12.8min finished\n",
      "Precision(avg): 0.758 (+/- 0.017)\n",
      "Recall(avg): 0.692 (+/- 0.022)\n",
      "F1-score(avg): 0.705 (+/- 0.021)\n"
     ]
    }
   ],
   "source": [
    "!python BoWV.py -m svm --kernel rbf --class_weight balanced --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoWV + GBDT\n",
    "\n",
    "__Command:__\n",
    "`!python BoWV.py -m gradient_boosting --loss deviance --estimators 500 --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove `\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.765 (vs. 0.800)\n",
    "\n",
    "Recall(avg): 0.774 (vs. 0.802)\n",
    "\n",
    "F1-score(avg): 0.759 (vs. 0.801)\n",
    "\n",
    "__Reflection:__\n",
    "They are missing the hyperpararmeteers. Regardless, it is pretty far off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "GloVe model loaded successfully.\n",
      "Tweets selected: 16905\n",
      "Features and labels loaded from pickled files.\n",
      "Model Type: gradient_boosting\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 19.6min finished\n",
      "Precision(avg): 0.765 (+/- 0.013)\n",
      "Recall(avg): 0.774 (+/- 0.012)\n",
      "F1-score(avg): 0.759 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "!python BoWV.py -m gradient_boosting --loss deviance --estimators 500 --jobs -2 -f GloVe/glove.twitter.27B.200d.txt -d 200 --seed 42 --tokenizer glove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "### CNN + Random Embedding\n",
    "\n",
    "__Command:__\n",
    "`!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights random --learn-embeddings`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.816 (vs. 0.813)\n",
    "\n",
    "Recall(avg): 0.816 (vs. 0.816)\n",
    "\n",
    "F1-score(avg): 0.816 (vs. 0.814)\n",
    "\n",
    "__Reflection:__\n",
    "Looks good! Note that the authors do not mention for how many epochs they trained the networks. I trained for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 28\n",
      "3450 embedding missed\n",
      "Model variation is CNN-rand\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 28, 200)       3402800     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 28, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 300)           240300      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 300)           0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 300)           0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             903         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 3)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,644,003\n",
      "Trainable params: 3,644,003\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "2019-10-05 20:29:58.269479: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.817434.\tAccuracy: 0.703571\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.708531.\tAccuracy: 0.732812\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.636865.\tAccuracy: 0.758185\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.408748.\tAccuracy: 0.838839\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.379630.\tAccuracy: 0.852344\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.359142.\tAccuracy: 0.859301\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.260756.\tAccuracy: 0.902232\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.243258.\tAccuracy: 0.908817\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.226457.\tAccuracy: 0.916146\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.169056.\tAccuracy: 0.942634\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.156666.\tAccuracy: 0.945759\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.147337.\tAccuracy: 0.948140\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.111978.\tAccuracy: 0.962946\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.103828.\tAccuracy: 0.965513\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.096984.\tAccuracy: 0.967411\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.086495.\tAccuracy: 0.971429\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.081599.\tAccuracy: 0.973103\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.076693.\tAccuracy: 0.975298\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.067275.\tAccuracy: 0.978348\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.064103.\tAccuracy: 0.979464\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.059071.\tAccuracy: 0.980729\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.055981.\tAccuracy: 0.981696\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.052424.\tAccuracy: 0.983036\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.049897.\tAccuracy: 0.984301\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.048847.\tAccuracy: 0.985714\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.046181.\tAccuracy: 0.985268\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.043066.\tAccuracy: 0.986012\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.042286.\tAccuracy: 0.986384\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.041050.\tAccuracy: 0.986496\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.037727.\tAccuracy: 0.987649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      1155\n",
      "           1       0.66      0.69      0.68       191\n",
      "           2       0.63      0.71      0.67       345\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1691\n",
      "   macro avg       0.72      0.74      0.73      1691\n",
      "weighted avg       0.79      0.79      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.741829.\tAccuracy: 0.701339\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.638864.\tAccuracy: 0.746429\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.576704.\tAccuracy: 0.770461\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.320548.\tAccuracy: 0.878125\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.280595.\tAccuracy: 0.892522\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.259678.\tAccuracy: 0.900893\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.180813.\tAccuracy: 0.935268\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.166230.\tAccuracy: 0.941071\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.153907.\tAccuracy: 0.945164\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.114378.\tAccuracy: 0.962054\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.109192.\tAccuracy: 0.962946\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.099530.\tAccuracy: 0.967262\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.084869.\tAccuracy: 0.971429\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.081089.\tAccuracy: 0.974107\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.076806.\tAccuracy: 0.974926\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.063769.\tAccuracy: 0.979911\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.064941.\tAccuracy: 0.977902\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.061077.\tAccuracy: 0.980060\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.056856.\tAccuracy: 0.982366\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.055999.\tAccuracy: 0.981362\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.052678.\tAccuracy: 0.982440\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.050007.\tAccuracy: 0.983259\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.047076.\tAccuracy: 0.984710\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.043164.\tAccuracy: 0.986384\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.046630.\tAccuracy: 0.983929\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.042948.\tAccuracy: 0.985045\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.041433.\tAccuracy: 0.986086\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.031941.\tAccuracy: 0.988393\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.034367.\tAccuracy: 0.988281\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.031496.\tAccuracy: 0.989807\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      1176\n",
      "           1       0.65      0.64      0.64       187\n",
      "           2       0.63      0.68      0.65       328\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1691\n",
      "   macro avg       0.71      0.72      0.72      1691\n",
      "weighted avg       0.79      0.79      0.79      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.845747.\tAccuracy: 0.675223\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.708180.\tAccuracy: 0.726897\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.637266.\tAccuracy: 0.753125\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.318868.\tAccuracy: 0.880357\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.285293.\tAccuracy: 0.892188\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.265327.\tAccuracy: 0.899926\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.184690.\tAccuracy: 0.931920\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.170531.\tAccuracy: 0.938504\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.159904.\tAccuracy: 0.943155\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.123474.\tAccuracy: 0.956250\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.117492.\tAccuracy: 0.959263\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.110053.\tAccuracy: 0.962054\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.099492.\tAccuracy: 0.969196\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.089882.\tAccuracy: 0.970759\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.084871.\tAccuracy: 0.972321\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.075133.\tAccuracy: 0.977232\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.070585.\tAccuracy: 0.978348\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.066739.\tAccuracy: 0.979390\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.067173.\tAccuracy: 0.977232\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.062504.\tAccuracy: 0.979464\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.058609.\tAccuracy: 0.980655\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.051348.\tAccuracy: 0.984152\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.050923.\tAccuracy: 0.984152\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.050077.\tAccuracy: 0.984821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.048335.\tAccuracy: 0.983929\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.047847.\tAccuracy: 0.984263\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.045784.\tAccuracy: 0.984970\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.045184.\tAccuracy: 0.986830\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.041895.\tAccuracy: 0.987388\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.040375.\tAccuracy: 0.987574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      1155\n",
      "           1       0.72      0.72      0.72       205\n",
      "           2       0.70      0.63      0.66       331\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1691\n",
      "   macro avg       0.76      0.74      0.75      1691\n",
      "weighted avg       0.81      0.81      0.81      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.873144.\tAccuracy: 0.660268\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.758676.\tAccuracy: 0.707924\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.685781.\tAccuracy: 0.737798\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.335062.\tAccuracy: 0.872991\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.306403.\tAccuracy: 0.883147\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.286844.\tAccuracy: 0.892262\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.197885.\tAccuracy: 0.922321\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.180309.\tAccuracy: 0.932924\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.169062.\tAccuracy: 0.937798\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.146411.\tAccuracy: 0.949330\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.136462.\tAccuracy: 0.952902\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.123929.\tAccuracy: 0.957738\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.104485.\tAccuracy: 0.964955\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.096997.\tAccuracy: 0.966629\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.094476.\tAccuracy: 0.966890\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.083348.\tAccuracy: 0.972545\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.079655.\tAccuracy: 0.972768\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.078083.\tAccuracy: 0.973065\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.080358.\tAccuracy: 0.973884\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.075825.\tAccuracy: 0.975670\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.070532.\tAccuracy: 0.976935\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.057403.\tAccuracy: 0.981027\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.054531.\tAccuracy: 0.983259\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.053226.\tAccuracy: 0.983929\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.054470.\tAccuracy: 0.982589\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.055452.\tAccuracy: 0.981808\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.052992.\tAccuracy: 0.982664\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.051838.\tAccuracy: 0.981920\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.049286.\tAccuracy: 0.983594\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.046053.\tAccuracy: 0.984896\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      1142\n",
      "           1       0.67      0.72      0.70       194\n",
      "           2       0.68      0.67      0.67       355\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1691\n",
      "   macro avg       0.74      0.75      0.74      1691\n",
      "weighted avg       0.80      0.80      0.80      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.030443.\tAccuracy: 0.653571\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.846493.\tAccuracy: 0.703125\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.756181.\tAccuracy: 0.729911\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.356508.\tAccuracy: 0.859375\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.335007.\tAccuracy: 0.870424\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.314582.\tAccuracy: 0.878497\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.225587.\tAccuracy: 0.915625\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.212232.\tAccuracy: 0.922433\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.197353.\tAccuracy: 0.927083\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.157946.\tAccuracy: 0.945536\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.146647.\tAccuracy: 0.948996\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.140991.\tAccuracy: 0.949330\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.127492.\tAccuracy: 0.957143\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.119982.\tAccuracy: 0.959263\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.112116.\tAccuracy: 0.961012\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.095283.\tAccuracy: 0.966295\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.091054.\tAccuracy: 0.968750\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.085856.\tAccuracy: 0.970685\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.079509.\tAccuracy: 0.971205\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.075539.\tAccuracy: 0.975000\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.071991.\tAccuracy: 0.975967\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.072181.\tAccuracy: 0.978795\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.069196.\tAccuracy: 0.979129\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.064370.\tAccuracy: 0.979911\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.060619.\tAccuracy: 0.980580\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.059743.\tAccuracy: 0.980580\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.056221.\tAccuracy: 0.981994\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.057842.\tAccuracy: 0.981473\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.055143.\tAccuracy: 0.983036\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.051413.\tAccuracy: 0.984077\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      1134\n",
      "           1       0.68      0.76      0.72       194\n",
      "           2       0.77      0.70      0.73       363\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1691\n",
      "   macro avg       0.77      0.78      0.77      1691\n",
      "weighted avg       0.83      0.82      0.82      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.086010.\tAccuracy: 0.645536\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.912377.\tAccuracy: 0.687500\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.812408.\tAccuracy: 0.717932\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.383573.\tAccuracy: 0.853348\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.362865.\tAccuracy: 0.860379\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.348255.\tAccuracy: 0.866369\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.239894.\tAccuracy: 0.911607\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.226785.\tAccuracy: 0.914844\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.215778.\tAccuracy: 0.919122\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.166850.\tAccuracy: 0.943304\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.161888.\tAccuracy: 0.942746\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.156976.\tAccuracy: 0.943527\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.129935.\tAccuracy: 0.949107\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.129147.\tAccuracy: 0.952567\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.122199.\tAccuracy: 0.956548\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.110243.\tAccuracy: 0.961607\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.105904.\tAccuracy: 0.964286\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.101130.\tAccuracy: 0.964955\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.085942.\tAccuracy: 0.971429\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.086407.\tAccuracy: 0.970871\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.082344.\tAccuracy: 0.972024\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.074290.\tAccuracy: 0.975893\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.073687.\tAccuracy: 0.976116\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.069361.\tAccuracy: 0.977381\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.064023.\tAccuracy: 0.982143\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.063304.\tAccuracy: 0.979799\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.061801.\tAccuracy: 0.980878\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.066123.\tAccuracy: 0.979018\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.062497.\tAccuracy: 0.979576\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.057990.\tAccuracy: 0.981771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1169\n",
      "           1       0.71      0.69      0.70       191\n",
      "           2       0.74      0.71      0.73       330\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1690\n",
      "   macro avg       0.78      0.76      0.77      1690\n",
      "weighted avg       0.83      0.83      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.025721.\tAccuracy: 0.643527\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.881616.\tAccuracy: 0.686049\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.798127.\tAccuracy: 0.713988\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.395786.\tAccuracy: 0.849777\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.370598.\tAccuracy: 0.857143\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.360065.\tAccuracy: 0.862277\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.253522.\tAccuracy: 0.900446\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.245093.\tAccuracy: 0.906920\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.235232.\tAccuracy: 0.909970\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.182785.\tAccuracy: 0.934375\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.178514.\tAccuracy: 0.935937\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.171130.\tAccuracy: 0.938690\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.139811.\tAccuracy: 0.951786\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.132658.\tAccuracy: 0.954464\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.128473.\tAccuracy: 0.955208\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.119439.\tAccuracy: 0.958259\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.119313.\tAccuracy: 0.958259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.112313.\tAccuracy: 0.960119\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.091431.\tAccuracy: 0.968750\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.095103.\tAccuracy: 0.966964\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.092931.\tAccuracy: 0.968229\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.083757.\tAccuracy: 0.970536\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.081412.\tAccuracy: 0.971205\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.077920.\tAccuracy: 0.972098\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.074322.\tAccuracy: 0.977679\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.073357.\tAccuracy: 0.977121\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.070471.\tAccuracy: 0.977753\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.063309.\tAccuracy: 0.979018\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.064530.\tAccuracy: 0.979799\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.060675.\tAccuracy: 0.981101\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1150\n",
      "           1       0.71      0.77      0.74       209\n",
      "           2       0.74      0.69      0.72       331\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1690\n",
      "   macro avg       0.78      0.78      0.78      1690\n",
      "weighted avg       0.83      0.83      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.081953.\tAccuracy: 0.642857\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.907646.\tAccuracy: 0.686607\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.817631.\tAccuracy: 0.712500\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.422137.\tAccuracy: 0.838839\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.396023.\tAccuracy: 0.848884\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.381934.\tAccuracy: 0.855804\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.279017.\tAccuracy: 0.893750\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.259378.\tAccuracy: 0.902790\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.249228.\tAccuracy: 0.906176\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.200524.\tAccuracy: 0.927455\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.194805.\tAccuracy: 0.930357\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.184805.\tAccuracy: 0.933333\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.152527.\tAccuracy: 0.947098\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.147619.\tAccuracy: 0.948438\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.145806.\tAccuracy: 0.949926\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.132028.\tAccuracy: 0.953571\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.129826.\tAccuracy: 0.954129\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.124836.\tAccuracy: 0.956696\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.111556.\tAccuracy: 0.962723\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.107441.\tAccuracy: 0.964174\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.103037.\tAccuracy: 0.964658\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.091168.\tAccuracy: 0.967187\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.085692.\tAccuracy: 0.969978\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.082382.\tAccuracy: 0.970982\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.083455.\tAccuracy: 0.972768\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.085550.\tAccuracy: 0.970759\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.082036.\tAccuracy: 0.972098\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.074428.\tAccuracy: 0.975893\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.072063.\tAccuracy: 0.976004\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.069377.\tAccuracy: 0.976562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      1119\n",
      "           1       0.75      0.70      0.72       209\n",
      "           2       0.76      0.67      0.71       362\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.79      0.76      0.77      1690\n",
      "weighted avg       0.82      0.82      0.82      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.175766.\tAccuracy: 0.636830\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.977132.\tAccuracy: 0.676228\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.876324.\tAccuracy: 0.700744\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.427631.\tAccuracy: 0.837946\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.404018.\tAccuracy: 0.843750\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.389585.\tAccuracy: 0.849033\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.287042.\tAccuracy: 0.892634\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.278534.\tAccuracy: 0.896094\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.266462.\tAccuracy: 0.899777\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.207592.\tAccuracy: 0.922545\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.199184.\tAccuracy: 0.926786\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.192718.\tAccuracy: 0.928423\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.168491.\tAccuracy: 0.939286\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.157843.\tAccuracy: 0.942076\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.151682.\tAccuracy: 0.944345\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.137562.\tAccuracy: 0.950223\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.130737.\tAccuracy: 0.953013\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.126870.\tAccuracy: 0.954688\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.114527.\tAccuracy: 0.960268\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.111821.\tAccuracy: 0.961049\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.105836.\tAccuracy: 0.963318\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.097152.\tAccuracy: 0.967634\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.094720.\tAccuracy: 0.968415\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.089455.\tAccuracy: 0.970536\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.087679.\tAccuracy: 0.968080\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.086162.\tAccuracy: 0.970089\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.081797.\tAccuracy: 0.971949\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.076790.\tAccuracy: 0.971652\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.075631.\tAccuracy: 0.972768\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.074066.\tAccuracy: 0.973512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      1166\n",
      "           1       0.73      0.76      0.74       194\n",
      "           2       0.76      0.76      0.76       330\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1690\n",
      "   macro avg       0.80      0.80      0.80      1690\n",
      "weighted avg       0.85      0.85      0.85      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.099484.\tAccuracy: 0.641518\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.940715.\tAccuracy: 0.680469\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.845013.\tAccuracy: 0.705952\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.426881.\tAccuracy: 0.839509\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.410145.\tAccuracy: 0.845536\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.400472.\tAccuracy: 0.848884\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.271658.\tAccuracy: 0.894420\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.271543.\tAccuracy: 0.896763\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.266153.\tAccuracy: 0.900000\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.206292.\tAccuracy: 0.922098\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.202747.\tAccuracy: 0.924107\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.196000.\tAccuracy: 0.927158\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.163729.\tAccuracy: 0.942187\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.162367.\tAccuracy: 0.943638\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.156732.\tAccuracy: 0.945759\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.132124.\tAccuracy: 0.952009\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.134406.\tAccuracy: 0.951562\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.131112.\tAccuracy: 0.952381\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.121331.\tAccuracy: 0.960045\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.115485.\tAccuracy: 0.960045\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.110096.\tAccuracy: 0.962277\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.099388.\tAccuracy: 0.962500\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.096222.\tAccuracy: 0.965625\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.091523.\tAccuracy: 0.968006\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.085379.\tAccuracy: 0.972991\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.081933.\tAccuracy: 0.973884\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.079609.\tAccuracy: 0.973735\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.075423.\tAccuracy: 0.977009\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.075728.\tAccuracy: 0.975446\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.072230.\tAccuracy: 0.976562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      1133\n",
      "           1       0.74      0.76      0.75       202\n",
      "           2       0.72      0.68      0.70       355\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1690\n",
      "   macro avg       0.78      0.77      0.77      1690\n",
      "weighted avg       0.82      0.82      0.82      1690\n",
      "\n",
      "weighted results are\n",
      "average precision is 0.816428\n",
      "average recall is 0.816153\n",
      "average f1 is 0.815898\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights random --learn-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "### CNN + GloVe\n",
    "\n",
    "__Command:__\n",
    "`!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights glove --learn-embeddings`\n",
    "\n",
    "__Result:__ \n",
    "\n",
    "replicated (vs. original)\n",
    "\n",
    "Precision(avg): 0.836 (vs. 0.839)\n",
    "\n",
    "Recall(avg): 0.837 (vs. 0.840)\n",
    "\n",
    "F1-score(avg): 0.835 (vs. 0.839)\n",
    "\n",
    "__Reflection:__\n",
    "Close enough. Note that the authors do not mention for how many epochs they trained the networks. I trained for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16905\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 28\n",
      "3450 embedding missed\n",
      "Model variation is CNN-rand\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 28, 200)       3402800     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 28, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 300)           240300      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 300)           0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 300)           0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             903         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 3)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,644,003\n",
      "Trainable params: 3,644,003\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "2019-10-05 21:19:33.939638: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.611778.\tAccuracy: 0.764286\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.565139.\tAccuracy: 0.781473\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.542019.\tAccuracy: 0.787202\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.432527.\tAccuracy: 0.821205\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.421606.\tAccuracy: 0.829911\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.416893.\tAccuracy: 0.830729\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.350413.\tAccuracy: 0.855134\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.345401.\tAccuracy: 0.859598\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.336043.\tAccuracy: 0.863021\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.298232.\tAccuracy: 0.880357\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.281177.\tAccuracy: 0.888170\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.275736.\tAccuracy: 0.891667\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.234814.\tAccuracy: 0.908259\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.227032.\tAccuracy: 0.912612\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.223618.\tAccuracy: 0.913095\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.193898.\tAccuracy: 0.925446\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.185703.\tAccuracy: 0.928237\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.179902.\tAccuracy: 0.931696\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.158831.\tAccuracy: 0.943304\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.153652.\tAccuracy: 0.946205\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.151265.\tAccuracy: 0.946875\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.139895.\tAccuracy: 0.947991\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.132040.\tAccuracy: 0.950112\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.126786.\tAccuracy: 0.952679\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.123993.\tAccuracy: 0.955134\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.117963.\tAccuracy: 0.956808\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.112084.\tAccuracy: 0.959003\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.105629.\tAccuracy: 0.960714\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.101538.\tAccuracy: 0.963393\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.098139.\tAccuracy: 0.965104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1155\n",
      "           1       0.70      0.75      0.72       191\n",
      "           2       0.77      0.68      0.72       345\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.78      0.77      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.910258.\tAccuracy: 0.689955\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.762965.\tAccuracy: 0.728013\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.686802.\tAccuracy: 0.747470\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.448283.\tAccuracy: 0.819643\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.430603.\tAccuracy: 0.829799\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.424351.\tAccuracy: 0.831771\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.358919.\tAccuracy: 0.854018\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.356665.\tAccuracy: 0.857924\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.350463.\tAccuracy: 0.860193\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.298787.\tAccuracy: 0.885268\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.291575.\tAccuracy: 0.887723\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.285656.\tAccuracy: 0.888765\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.247718.\tAccuracy: 0.902455\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.245526.\tAccuracy: 0.903348\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.242210.\tAccuracy: 0.905134\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.209561.\tAccuracy: 0.920312\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.214087.\tAccuracy: 0.918973\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.205815.\tAccuracy: 0.922991\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.173755.\tAccuracy: 0.933036\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.175276.\tAccuracy: 0.933036\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.170539.\tAccuracy: 0.936161\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.156533.\tAccuracy: 0.941295\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.154781.\tAccuracy: 0.942299\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.150208.\tAccuracy: 0.944122\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.131109.\tAccuracy: 0.953348\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.133377.\tAccuracy: 0.951004\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.132783.\tAccuracy: 0.950818\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.131917.\tAccuracy: 0.952902\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.125384.\tAccuracy: 0.954911\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.121004.\tAccuracy: 0.955580\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1176\n",
      "           1       0.71      0.73      0.72       187\n",
      "           2       0.73      0.68      0.70       328\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.77      0.77      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.331867.\tAccuracy: 0.672321\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 1.015055.\tAccuracy: 0.715290\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.875632.\tAccuracy: 0.733929\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.455373.\tAccuracy: 0.824554\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.448806.\tAccuracy: 0.824888\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.441811.\tAccuracy: 0.826562\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.374208.\tAccuracy: 0.851562\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.374020.\tAccuracy: 0.855246\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.368251.\tAccuracy: 0.855804\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.322826.\tAccuracy: 0.870536\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.320571.\tAccuracy: 0.873772\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.312895.\tAccuracy: 0.878125\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.277698.\tAccuracy: 0.892634\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.274671.\tAccuracy: 0.894420\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.268798.\tAccuracy: 0.896726\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.230076.\tAccuracy: 0.909821\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.231869.\tAccuracy: 0.909152\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.227347.\tAccuracy: 0.912351\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.210331.\tAccuracy: 0.918973\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.206171.\tAccuracy: 0.922656\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.201034.\tAccuracy: 0.924628\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.175672.\tAccuracy: 0.935937\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.179118.\tAccuracy: 0.932813\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.176569.\tAccuracy: 0.933557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.157955.\tAccuracy: 0.942411\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.150249.\tAccuracy: 0.945871\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.150660.\tAccuracy: 0.944940\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.137948.\tAccuracy: 0.948438\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.137960.\tAccuracy: 0.949554\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.138997.\tAccuracy: 0.948363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1155\n",
      "           1       0.77      0.77      0.77       205\n",
      "           2       0.75      0.61      0.68       331\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.79      0.76      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.044777.\tAccuracy: 0.681696\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.878581.\tAccuracy: 0.714844\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.789872.\tAccuracy: 0.731845\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.463239.\tAccuracy: 0.815625\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.460207.\tAccuracy: 0.820424\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.455724.\tAccuracy: 0.823289\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.386483.\tAccuracy: 0.845536\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.381901.\tAccuracy: 0.847991\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.384460.\tAccuracy: 0.845015\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.324955.\tAccuracy: 0.866741\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.327501.\tAccuracy: 0.867634\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.324331.\tAccuracy: 0.870610\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.302589.\tAccuracy: 0.878125\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.294564.\tAccuracy: 0.882589\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.287421.\tAccuracy: 0.885863\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.248923.\tAccuracy: 0.902902\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.245493.\tAccuracy: 0.904018\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.243378.\tAccuracy: 0.904464\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.220995.\tAccuracy: 0.917188\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.218572.\tAccuracy: 0.916853\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.214416.\tAccuracy: 0.918155\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.182493.\tAccuracy: 0.929241\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.185008.\tAccuracy: 0.929129\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.184567.\tAccuracy: 0.929167\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.163794.\tAccuracy: 0.940625\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.166361.\tAccuracy: 0.939732\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.165542.\tAccuracy: 0.939881\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.156203.\tAccuracy: 0.941295\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.149761.\tAccuracy: 0.944866\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.146483.\tAccuracy: 0.946205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1142\n",
      "           1       0.72      0.70      0.71       194\n",
      "           2       0.81      0.64      0.72       355\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1691\n",
      "   macro avg       0.80      0.75      0.77      1691\n",
      "weighted avg       0.83      0.83      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.468732.\tAccuracy: 0.656250\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 1.106551.\tAccuracy: 0.705469\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.943589.\tAccuracy: 0.723363\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.477379.\tAccuracy: 0.813839\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.475382.\tAccuracy: 0.814509\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.472581.\tAccuracy: 0.813765\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.397186.\tAccuracy: 0.844866\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.398312.\tAccuracy: 0.845647\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.397166.\tAccuracy: 0.843452\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.346114.\tAccuracy: 0.858482\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.346663.\tAccuracy: 0.862723\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.341573.\tAccuracy: 0.865253\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.304372.\tAccuracy: 0.880580\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.299026.\tAccuracy: 0.885603\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.297232.\tAccuracy: 0.886161\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.260365.\tAccuracy: 0.896429\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.257276.\tAccuracy: 0.900446\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.255659.\tAccuracy: 0.900446\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.240935.\tAccuracy: 0.902902\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.231100.\tAccuracy: 0.911272\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.227897.\tAccuracy: 0.912351\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.212308.\tAccuracy: 0.921205\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.206466.\tAccuracy: 0.922991\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.204198.\tAccuracy: 0.923512\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.183791.\tAccuracy: 0.927455\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.177966.\tAccuracy: 0.933594\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.174007.\tAccuracy: 0.936086\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.163488.\tAccuracy: 0.937723\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.162719.\tAccuracy: 0.938170\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.156691.\tAccuracy: 0.941741\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1134\n",
      "           1       0.71      0.82      0.76       194\n",
      "           2       0.80      0.66      0.72       363\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1691\n",
      "   macro avg       0.79      0.79      0.79      1691\n",
      "weighted avg       0.84      0.84      0.83      1691\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.275259.\tAccuracy: 0.673214\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 1.027500.\tAccuracy: 0.702121\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.898289.\tAccuracy: 0.722173\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.494449.\tAccuracy: 0.808929\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.486608.\tAccuracy: 0.810379\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.482124.\tAccuracy: 0.811756\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.403469.\tAccuracy: 0.836830\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.402703.\tAccuracy: 0.841518\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.401292.\tAccuracy: 0.841443\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.353844.\tAccuracy: 0.863393\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.356396.\tAccuracy: 0.859598\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.354843.\tAccuracy: 0.859301\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.317295.\tAccuracy: 0.878125\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.311894.\tAccuracy: 0.882143\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.309529.\tAccuracy: 0.882440\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.276987.\tAccuracy: 0.892634\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.273480.\tAccuracy: 0.895647\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.271010.\tAccuracy: 0.893973\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.238518.\tAccuracy: 0.909821\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.237238.\tAccuracy: 0.911607\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.234725.\tAccuracy: 0.911235\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.210856.\tAccuracy: 0.916295\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.213338.\tAccuracy: 0.918750\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.207133.\tAccuracy: 0.920759\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.190459.\tAccuracy: 0.927009\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.186045.\tAccuracy: 0.928795\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.185797.\tAccuracy: 0.929390\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.170182.\tAccuracy: 0.936161\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.171337.\tAccuracy: 0.936272\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.166323.\tAccuracy: 0.937723\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1169\n",
      "           1       0.73      0.80      0.76       191\n",
      "           2       0.78      0.70      0.74       330\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1690\n",
      "   macro avg       0.80      0.80      0.80      1690\n",
      "weighted avg       0.85      0.85      0.85      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.134100.\tAccuracy: 0.668527\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.917433.\tAccuracy: 0.708036\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.819085.\tAccuracy: 0.727902\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.481352.\tAccuracy: 0.809821\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.479011.\tAccuracy: 0.814174\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.478295.\tAccuracy: 0.813988\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.412890.\tAccuracy: 0.834375\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.409066.\tAccuracy: 0.838393\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.405509.\tAccuracy: 0.837798\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.364783.\tAccuracy: 0.854018\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.361078.\tAccuracy: 0.855692\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.359097.\tAccuracy: 0.856994\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.316507.\tAccuracy: 0.871205\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.312158.\tAccuracy: 0.875000\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.312657.\tAccuracy: 0.875000\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.279952.\tAccuracy: 0.891964\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.276856.\tAccuracy: 0.894085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.276481.\tAccuracy: 0.892560\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.248141.\tAccuracy: 0.906027\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.250129.\tAccuracy: 0.903571\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.248791.\tAccuracy: 0.902976\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.216819.\tAccuracy: 0.914509\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.211454.\tAccuracy: 0.917634\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.212014.\tAccuracy: 0.916964\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.194787.\tAccuracy: 0.924330\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.193829.\tAccuracy: 0.928125\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.193040.\tAccuracy: 0.928869\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.165726.\tAccuracy: 0.937500\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.167136.\tAccuracy: 0.935603\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.165930.\tAccuracy: 0.935863\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      1150\n",
      "           1       0.73      0.82      0.77       209\n",
      "           2       0.78      0.63      0.70       331\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1690\n",
      "   macro avg       0.79      0.78      0.78      1690\n",
      "weighted avg       0.83      0.84      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.123290.\tAccuracy: 0.662054\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.925633.\tAccuracy: 0.702121\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.827379.\tAccuracy: 0.721429\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.499801.\tAccuracy: 0.804018\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.495707.\tAccuracy: 0.801674\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.491452.\tAccuracy: 0.803646\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.425532.\tAccuracy: 0.828348\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.422831.\tAccuracy: 0.833482\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.417653.\tAccuracy: 0.834301\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.386254.\tAccuracy: 0.845089\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.380236.\tAccuracy: 0.848103\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.377299.\tAccuracy: 0.849256\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.331157.\tAccuracy: 0.866964\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.328188.\tAccuracy: 0.873214\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.328198.\tAccuracy: 0.870908\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.296753.\tAccuracy: 0.878125\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.296144.\tAccuracy: 0.882589\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.291911.\tAccuracy: 0.883780\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.261692.\tAccuracy: 0.896205\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.260486.\tAccuracy: 0.894643\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.257065.\tAccuracy: 0.898735\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.230629.\tAccuracy: 0.910714\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.221900.\tAccuracy: 0.914062\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.218229.\tAccuracy: 0.914881\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.211034.\tAccuracy: 0.921652\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.202368.\tAccuracy: 0.922098\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.200836.\tAccuracy: 0.921949\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.176258.\tAccuracy: 0.936161\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.176041.\tAccuracy: 0.933371\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.176775.\tAccuracy: 0.933110\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      1119\n",
      "           1       0.74      0.72      0.73       209\n",
      "           2       0.83      0.65      0.73       362\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1690\n",
      "   macro avg       0.81      0.76      0.78      1690\n",
      "weighted avg       0.83      0.84      0.83      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.072463.\tAccuracy: 0.668973\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.895221.\tAccuracy: 0.708036\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.797830.\tAccuracy: 0.726265\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.496751.\tAccuracy: 0.800446\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.499556.\tAccuracy: 0.802121\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.492973.\tAccuracy: 0.803051\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.422382.\tAccuracy: 0.833259\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.428592.\tAccuracy: 0.830357\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.424487.\tAccuracy: 0.831771\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.375028.\tAccuracy: 0.845089\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.376617.\tAccuracy: 0.846540\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.373189.\tAccuracy: 0.849330\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.339910.\tAccuracy: 0.859821\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.330172.\tAccuracy: 0.866518\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.324966.\tAccuracy: 0.869420\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.301854.\tAccuracy: 0.880580\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.295808.\tAccuracy: 0.884263\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.292573.\tAccuracy: 0.884821\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.261236.\tAccuracy: 0.897545\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.264518.\tAccuracy: 0.896205\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.261167.\tAccuracy: 0.898363\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.224041.\tAccuracy: 0.912277\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.224910.\tAccuracy: 0.913616\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.226574.\tAccuracy: 0.910789\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.202579.\tAccuracy: 0.918973\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.202309.\tAccuracy: 0.921540\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.199623.\tAccuracy: 0.920908\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.180669.\tAccuracy: 0.931027\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.181676.\tAccuracy: 0.929464\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.181027.\tAccuracy: 0.930804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1166\n",
      "           1       0.78      0.81      0.80       194\n",
      "           2       0.85      0.68      0.76       330\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1690\n",
      "   macro avg       0.84      0.81      0.82      1690\n",
      "weighted avg       0.87      0.87      0.87      1690\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 1.169500.\tAccuracy: 0.668527\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.941510.\tAccuracy: 0.705357\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.830977.\tAccuracy: 0.726265\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.498537.\tAccuracy: 0.796875\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.499253.\tAccuracy: 0.798326\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.492625.\tAccuracy: 0.803720\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.417117.\tAccuracy: 0.831027\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.416822.\tAccuracy: 0.833817\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.416657.\tAccuracy: 0.833110\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.362849.\tAccuracy: 0.851562\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.361338.\tAccuracy: 0.857254\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.357154.\tAccuracy: 0.859598\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.323852.\tAccuracy: 0.870536\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.326754.\tAccuracy: 0.869978\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.323313.\tAccuracy: 0.870833\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.286814.\tAccuracy: 0.883036\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.286723.\tAccuracy: 0.886384\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.281434.\tAccuracy: 0.888542\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.255230.\tAccuracy: 0.903125\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.254851.\tAccuracy: 0.903906\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.250613.\tAccuracy: 0.904464\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.216765.\tAccuracy: 0.919643\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.218598.\tAccuracy: 0.917857\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.215778.\tAccuracy: 0.919345\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.195261.\tAccuracy: 0.928795\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.187371.\tAccuracy: 0.929018\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.185596.\tAccuracy: 0.929688\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.174074.\tAccuracy: 0.934375\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.173227.\tAccuracy: 0.934040\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.169337.\tAccuracy: 0.935491\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1133\n",
      "           1       0.75      0.75      0.75       202\n",
      "           2       0.82      0.63      0.71       355\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1690\n",
      "   macro avg       0.81      0.76      0.78      1690\n",
      "weighted avg       0.83      0.83      0.83      1690\n",
      "\n",
      "weighted results are\n",
      "average precision is 0.836167\n",
      "average recall is 0.837447\n",
      "average f1 is 0.834883\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "!python cnn.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --epochs 10 --batch-size 128 --folds 10 --initialize-weights glove --learn-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
